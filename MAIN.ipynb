{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Call the API with my variables for my research"
      ],
      "metadata": {
        "id": "Nu7m15GcZfnS"
      },
      "id": "Nu7m15GcZfnS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> List of some states \"46 SD\", \"47 TN\",\"10 DE\", \"2 AK\",\"5 AR\",\"24 MD\",\"31 NE\"\n",
        "\n",
        "CBSA:\n",
        "\n",
        "\"46 SD\",\n",
        "* \"43620 Sioux Falls, SD\",\n",
        "\n",
        "\"47 TN\"\n",
        "* \"16860 Chattanooga, TN-GA\",\n",
        "* \"28940 Knoxville, TN\",\n",
        "* \"34980\": \"Nashville-Davidson--Murfreesboro--Franklin, TN\",\n",
        "* \"28700\": \"Kingsport-Bristol-Bristol, TN-VA\",\n",
        "* \"32820\": \"Memphis, TN-MS-AR\",\n",
        "* \"17300\": \"Clarksville, TN-KY\",\n",
        "* \"27740\": \"Johnson City, TN\",\n",
        "* \"17420\": \"Cleveland, TN\",\n",
        "\n",
        "\"10 DE\"\n",
        "* \"20100 Dover, DE\",\n",
        "* \"428\": \"Philadelphia-Reading-Camden, PA-NJ-DE-MD\",\n",
        "* \"41540\": \"Salisbury, MD-DE\",\n",
        "*\n",
        "* 0 city for \"2 AK\"\n",
        "\n",
        "\"5 AR\",\n",
        "* \"22900 Fort Smith, AR-OK\",\n",
        "* \"30780 Little Rock-North Little Rock-Conway, AR\",\n",
        "* \"22220 Fayetteville-Springdale-Rogers, AR-MO\",\n",
        "* \"38220 Pine Bluff, AR\",\n",
        "* \"32820 Memphis, TN-MS-AR\",\n",
        "*\n",
        "\"24 MD\",\n",
        "* \"25180\": \"Hagerstown-Martinsburg, MD-WV\",\n",
        "* \"428\": \"Philadelphia-Reading-Camden, PA-NJ-DE-MD\",\n",
        "* \"12580\": \"Baltimore-Columbia-Towson, MD\",\n",
        "* \"37980\": \"Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\",\n",
        "* \"15680\": \"California-Lexington Park, MD\",\n",
        "* \"41540\": \"Salisbury, MD-DE\","
      ],
      "metadata": {
        "id": "MiS6CIJ8WuA8"
      },
      "id": "MiS6CIJ8WuA8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CONSTANTES"
      ],
      "metadata": {
        "id": "Wf-TQOlWDpR-"
      },
      "id": "Wf-TQOlWDpR-"
    },
    {
      "cell_type": "code",
      "source": [
        "# (10) IMPORT LIBRARY\n",
        "import requests\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import json\n",
        "import logging"
      ],
      "metadata": {
        "id": "IWRGDOLjvDDP"
      },
      "id": "IWRGDOLjvDDP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (20) CONSTANTES\n",
        "\n",
        "#Dict of all states\n",
        "all_states = requests.get('https://api.census.gov/data/2024/cps/basic/jan/variables.json')\n",
        "states = json.loads(all_states.text)\n",
        "states_dict = states['variables']['STATE']['values']['item']\n",
        "states = [state for state in states_dict.keys()]\n",
        "\n",
        "#All year of the study\n"
      ],
      "metadata": {
        "id": "uB5R3hshb3YQ"
      },
      "id": "uB5R3hshb3YQ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calling the API (1st step)"
      ],
      "metadata": {
        "id": "UfTbNpBzVvFH"
      },
      "id": "UfTbNpBzVvFH"
    },
    {
      "cell_type": "code",
      "source": [
        "# (30) CLASS API and Decorator [log_activity2]\n",
        "\n",
        "def log_activity2(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # Create a logger\n",
        "        logger = logging.getLogger('activity_logger')\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        # Create a file handler and set the logging format\n",
        "        file_handler = logging.FileHandler('activity.log')\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "\n",
        "        # Add the file handler to the logger\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        # Log the activity before calling the wrapped function\n",
        "        logger.info(f'Activity: {func.__name__}')\n",
        "\n",
        "        # Call the wrapped function\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class API:\n",
        "  \"\"\"This generic class API will handle at once all request to the CPS api\n",
        "  How to?:\n",
        "  > instanciate a variable at once, then use it to browse through all variables (not data) on the Census API json file\n",
        "  > example api:    api=API()\n",
        "\n",
        "  Properties:\n",
        "  > allVars_dict (variable): a dict of all variables for each 'year' (key)\n",
        "  > examples:\n",
        "    - api.allVars_dict[2023]        * to se all the variables (dict) in 2023\n",
        "    - 'GTCBSA' in api.allVars_dict[2024].keys() *                is <GTCBSA> in 2024?\n",
        "    - api.allState_dict[2021]       * all stateID:description in year 2021\"\"\"\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    self.get()\n",
        "\n",
        "  @log_activity2\n",
        "  def get(self):\n",
        "    self.allVars_dict = {year_: year_vars for year_, year_vars in \\\n",
        "            zip(self.allYearList(), [json.loads(requests.get('https://api.census.gov/data/'+ str(year_) +'/cps/basic/jan/variables.json').text)['variables'] for year_ in self.allYearList()])}\n",
        "\n",
        "  def store(self):\n",
        "    pass\n",
        "\n",
        "  @log_activity2\n",
        "  def allStatesIdList(self, year:int=2020):\n",
        "    return list(self.allVars_dict[year]['GESTFIPS']['values']['item'].keys())\n",
        "\n",
        "  @log_activity2\n",
        "  def allMonthList3TLA(self):\n",
        "    month_dict = {1:\"jan\",2:\"feb\",3:\"mar\",4:\"apr\",5:\"may\",6:\"jun\",7:\"jul\",8:\"aug\",9: \"sep\",10: \"oct\",11:\"nov\",12:\"dec\"}\n",
        "    #return next(key for key, value in month_dict.items() if value == m)\n",
        "    return list(month_dict.values())\n",
        "\n",
        "  def allYearList(self):\n",
        "    return range(2010, 1+dt.now().year)\n",
        "\n",
        "  @log_activity2\n",
        "  def getVarsNameFromUrl(self, url):\n",
        "    return re.findall(r'([A-Z]+)', url)\n",
        "\n",
        "\n",
        "api=API()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AkeD9fuuu7V",
        "outputId": "0ed374ed-e8de-4dda-e25f-481b7680fa49"
      },
      "id": "3AkeD9fuuu7V",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Activity: get\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (40) CLASS MIXCOMP\n",
        "#Decorator to track API response time\n",
        "def track_response_time(func):\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(self, *args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        response_time = end_time - start_time\n",
        "        self.response_time = response_time  # Store in the class\n",
        "        print(f\"Function: '{func.__name__}()'. Census API query took: {response_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "#Class for unit-request (specific State, specific Year, specific Month)\n",
        "class MixComp:\n",
        "  \"\"\"\n",
        "This class will pull the Mix composition about the US population from one state.\n",
        "Code\t    Label\n",
        "tabulate  Counts of instances\n",
        "PEMNTVTY\tDemographics-native country of mother\n",
        "PEMARITL\tDemographics-marital status\n",
        "PESEX\t    Demographics-sex\n",
        "PRCITSHP\tDemographics-United States citizenship group\n",
        "GTCBSA\t  Demographics-city level\n",
        "STATE\t    FIPS STATE Code\n",
        "GTCBSA\t  Demographics-city level\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, stateID, year, month):\n",
        "      key = '&key='+'804d0a1a18d1de70764950c78e2a3a42d3d45e48'\n",
        "      self.url = 'https://api.census.gov/data/'+ str(year) +'/cps/basic/'+ month + '?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:' + str(stateID) + key\n",
        "      self.stateID = stateID\n",
        "      self.year = year\n",
        "      self.month = month\n",
        "      self.response_time = 0 # how long the API took to run on Census CPS\n",
        "      self.dataAPI = None\n",
        "      self.dataText = None\n",
        "      self.data4Df = []\n",
        "      self.df = pd.DataFrame(None) #Will contain the final df(dataframe)\n",
        "      self.initLogger()\n",
        "\n",
        "  def initLogger(self):\n",
        "      # Create a logger\n",
        "      self.logger = logging.getLogger('activity_logger')\n",
        "      self.logger.setLevel(logging.INFO)\n",
        "      # Create a file handler and set the logging format\n",
        "      file_handler = logging.FileHandler('activity.log')\n",
        "      formatter = logging.Formatter('%(asctime)s - %(levelname)s - [w86] %(message)s')\n",
        "      file_handler.setFormatter(formatter)\n",
        "      # Add the file handler to the logger\n",
        "      self.logger.addHandler(file_handler)\n",
        "\n",
        "  def __str__(self):\n",
        "      return f\"\"\"\n",
        "      Mix Composition of the US population: stateID:={self.stateID}, month={self.month}, year={self.year}\n",
        "      Dataframe head:\n",
        "         {self.df.head(3)}\"\"\"\n",
        "\n",
        "  def __repr__(self):\n",
        "      return f\"MixComp({self.stateID}, {self.year}, {self.month})\"\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.df.shape[0]\n",
        "\n",
        "  def __add__(self, other):\n",
        "      return pd.concat([self.df, other.df], axis=0)\n",
        "\n",
        "  # to convert in class\n",
        "  def checkVariable(self, year, url):\n",
        "      \"\"\"\n",
        "      this function will check if a set of variables are declared on the Census API. Using the an url as input. Vars are in ALL_CAPS\n",
        "      \"\"\"\n",
        "      api=API()\n",
        "      api.get()\n",
        "      matches = api.getVarsNameFromUrl(url)\n",
        "      cps_vars = api.allVars_dict[year].keys()\n",
        "      res = dict()\n",
        "      for var in matches:\n",
        "        res[var] = True if var in cps_vars else False\n",
        "      res['status'] = all([status for status in res.values()])\n",
        "      return res\n",
        "\n",
        "  @track_response_time\n",
        "  def get(self):\n",
        "\n",
        "      #This section will validate all variables and replace the city's with the right one if year>=2024\n",
        "#      check = self.checkVariable(self.year, self.url)\n",
        "#      print (f\"checkVariable() = {check}\")\n",
        "#      if not check['status']:\n",
        "#        print(f\"BEFORE - Variables = {check}\")\n",
        "#        if (self.year>=2024) and ('CBSA' not in check.keys()): #before 2024, City variable in 'GTCBSA', starting on 2024, City variable was 'CBSA'\n",
        "#          self.url = re.sub('GTCBSA', 'CBSA', self.url)\n",
        "#          print(f\"AFTER -  Variables = {self.checkVariable(self.year, self.url)}\\nNew URL: {self.url}\")\n",
        "#        else:\n",
        "#          raise(f\"Please check all your Census variables. Unable to find some in the API call. Variables = {check}\")\n",
        "\n",
        "      try:\n",
        "        # download the Demographics_Native_Country_Of_Mother for Mix-Compostion\n",
        "        self.dataAPI = requests.get(self.url)\n",
        "        return dict({'response time in secs': round(self.response_time,0), 'status': True if 200==self.dataAPI.status_code else False, 'code':self.dataAPI.status_code, 'comment': 'url:' + self.url})\n",
        "        None\n",
        "      except requests.exceptions.RequestException as e:\n",
        "          # Handle connection errors or HTTP errors\n",
        "          raise(\"STOP ERROR: Tools for Data Science - Semester Project: An error occurred:\\n [[[[\", e, \"]]]]\")\n",
        "\n",
        "      except AttributeError:\n",
        "          raise(\"STOP ERROR: Please check your variable name!\")\n",
        "\n",
        "  def cleaning(self):\n",
        "      self.dataText = self.dataAPI.text\n",
        "      pattern_cleaning = r'\\[0,.*?\\],?\\n?' #remove the data with no tabulate information (tabulate=0)\n",
        "      self.dataText = re.sub(pattern_cleaning, '', self.dataText)\n",
        "      pattern_cleaning = r'\\n' #remove retunr line\n",
        "      self.dataText = re.sub(pattern_cleaning, '', self.dataText)\n",
        "      self.logger.info(f'> Cleaning dataAPI but removing data with no tabulate information (tabulate=0)')\n",
        "\n",
        "  def preping(self):\n",
        "      ##Separe cols from data (numbers)\n",
        "      pattern = r'.*?(\\[\"tabulate\".*?\"GTCBSA\"\\]),([\\s\\S]*)'\n",
        "      matches = re.search(pattern, self.dataText)\n",
        "      data_cols = matches.group(1)\n",
        "      data_vals = matches.group(2)[:-1] #removing the last char \"]\" at the end.\n",
        "\n",
        "      self.data_cols = re.findall(r'\"(.*?)\"', data_cols) #Transform string_column in List_column\n",
        "\n",
        "      #Transform string_row in List of Lists then Matrix\n",
        "      rows = re.findall(r'\\[(.*?)\\]', data_vals)\n",
        "      for row in rows:\n",
        "        row_list = re.findall(r'-?\\d+(?:\\.\\d+)?', row)\n",
        "        self.data4Df.append([int(elt) for elt in row_list])\n",
        "\n",
        "      self.logger.info(f'> len(self.data4Df): {len(self.data4Df)}')\n",
        "\n",
        "  def buildingDf(self):\n",
        "      \"\"\"\n",
        "      ##Definition of variables:\n",
        "      * tabulate: represents the information related to population counts.\n",
        "      * state: column provides information about the state\n",
        "      1. PEMNTVTY Demographics-native country of mother\n",
        "      2. PEMARITL Demographics-marital status\n",
        "      3. PESEX Demographics-sex\n",
        "      4. PRCITSHP Demographics-United States citizenship group\n",
        "      5. GTCBSA Demographics-city level\n",
        "      We will understand the population composition by state about how mixed it is based on the native country of mothers,\n",
        "      marital status distribution, gender demographics, citizenship status, at the city-level characteristics.\n",
        "      This data can be used to uncover trends, patterns, and insights into the social and cultural fabric of the US population.\n",
        "      \"\"\"\n",
        "      ##Convert the result to the Df **mix_composition**\n",
        "      self.df = pd.DataFrame(self.data4Df, columns=self.data_cols)\n",
        "\n",
        "      ##Building the YYYYMM column\n",
        "      self.df['YYYYMM'] = pd.Series([dt.strptime(str(self.year)+ '-' +str(self.month), \"%Y-%b\") for _ in range(self.df.shape[0])])\n",
        "\n",
        "      self.logger.info(f'> Built Dataframe for stateiD:{self.stateID}, YYYYMM:{str(self.year)}-{str(self.month)}')\n",
        "\n",
        "  def save(self, path=''):\n",
        "      try:\n",
        "        if path == '':\n",
        "          stateID = '0'+ str(self.stateID) if len(self.stateID)<2 else str(self.stateID) #fixing stateID in 2 digits\n",
        "          path = str(self.year)+'-'+ str(self.month)+'-'+ str(stateID)+'-MixComp.csv'\n",
        "        r = self.df.to_csv( path, index=False)\n",
        "        self.logger.info(f'> Created CSV file: {path}')\n",
        "        return r\n",
        "      except FileNotFoundError:\n",
        "        raise (f'Check the path {path} of the file')\n",
        "\n",
        "  def build(self):\n",
        "      self.logger.info(f'> Called main(self) method - Entrance')\n",
        "      self.logger.info(f'> Input Variables = self.url: {self.url}, self.stateID: {self.stateID}, self.year: {self.year}, self.month: {self.month}')\n",
        "\n",
        "      self.logger.info(f'> Called main(self) - get() method - Will take some time usually 3-5min')\n",
        "      res = self.get()\n",
        "      self.logger.info(f'Called main(self) - line: get() method - Result:{res}')\n",
        "\n",
        "      self.cleaning()\n",
        "      self.preping()\n",
        "      self.buildingDf(); self.logger.info(f'> Called main(self) - buildingDf() method')\n",
        "\n",
        "      self.logger.info(f'> Called main(self) - save() method')\n",
        "      self.save()\n",
        "\n",
        "      self.logger.info(f'> Called main(self) method - End')\n"
      ],
      "metadata": {
        "id": "pkTeNx4nLZy8"
      },
      "id": "pkTeNx4nLZy8",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (60) Going through All Months at once\n",
        "for year in api.allYearList():\n",
        "  for stateID in api.allStatesIdList(): #['31', '47']:\n",
        "    for month in api.allMonthList3TLA(): #['jan', 'feb']:\n",
        "      dataA = MixComp(stateID=stateID, year=year, month=month)\n",
        "      dataA.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "r0MvrQ9yjoZR",
        "outputId": "9e207c61-e116-432a-ba72-79548fcb6f77"
      },
      "id": "r0MvrQ9yjoZR",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> Called main(self) method - Entrance\n",
            "INFO:activity_logger:> Input Variables = self.url: https://api.census.gov/data/2010/cps/basic/jan?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:31&key=804d0a1a18d1de70764950c78e2a3a42d3d45e48, self.stateID: 31, self.year: 2010, self.month: jan\n",
            "INFO:activity_logger:> Called main(self) - get() method - Will take some time usually 3-5min\n",
            "INFO:activity_logger:Called main(self) - line: get() method - Result:{'response time in secs': 0, 'status': True, 'code': 200, 'comment': 'url:https://api.census.gov/data/2010/cps/basic/jan?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:31&key=804d0a1a18d1de70764950c78e2a3a42d3d45e48'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function: 'get()'. Census API query took: 176.77804517745972 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> Cleaning dataAPI but removing data with no tabulate information (tabulate=0)\n",
            "INFO:activity_logger:> len(self.data4Df): 195\n",
            "INFO:activity_logger:> Built Dataframe for stateiD:31, YYYYMM:2010-jan\n",
            "INFO:activity_logger:> Called main(self) - buildingDf() method\n",
            "INFO:activity_logger:> Called main(self) - save() method\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "exceptions must derive from BaseException",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-23f9c1741a40>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    161\u001b[0m           \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-MixComp.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'> Created CSV file: {path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3772\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3773\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         )\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8bda1df73dc1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'jan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#api.allMonthList3TLA()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdataA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMixComp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2010\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdataA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-23f9c1741a40>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'> Called main(self) - save() method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'> Called main(self) method - End'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-23f9c1741a40>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Check the path {path} of the file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (50) TEST\n",
        "stateID = states[1] #47 #range(1-56), without 3, 7, 14, 43\n",
        "year = 2023 # range(2010-2023)\n",
        "month = month_dict[10] #range(1-12)\n",
        "#dataA = MixComp(stateID, year, month)\n",
        "#dataA.build()\n",
        "\n",
        "stateID = states[2] #range(1-56), without 3, 7, 14, 43\n",
        "year = 2015 # range(2010-2023)\n",
        "month = month_dict[2] #range(1-12)\n",
        "#dataB = MixComp(stateID, year, month)\n",
        "#dataB.build()\n",
        "\n",
        "#dataR = dataA + dataB\n",
        "#dataR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IWkgVLw8gwB",
        "outputId": "13cf07ff-859d-4e1a-cfbd-127334988ba7"
      },
      "id": "_IWkgVLw8gwB",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> Called main(self) method - Entrance\n",
            "INFO:activity_logger:> Called main(self) - get() method - Will take some time usually 3-5min\n",
            "INFO:activity_logger:Called main(self) - line: get() method - Result:{'response time in secs': 0, 'status': True, 'code': 200, 'comment': 'url:https://api.census.gov/data/2023/cps/basic/oct?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:47&key=804d0a1a18d1de70764950c78e2a3a42d3d45e48'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function: 'get()'. Census API query took: 184.5014727115631 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> Cleaning dataAPI but removing data with no tabulate information (tabulate=0)\n",
            "INFO:activity_logger:> len(self.data4Df): 247\n",
            "INFO:activity_logger:> Called main(self) - buildingDf() method\n",
            "INFO:activity_logger:> Built Dataframe for stateiD:47, YYYYMM:2023-oct\n",
            "INFO:activity_logger:> Called main(self) - save() method - Beginning\n",
            "INFO:activity_logger:> Created CSV file: 2023-oct-MixComp.csv\n",
            "INFO:activity_logger:> Called main(self) - save() method - End\n",
            "INFO:activity_logger:> Called main(self) method - End\n",
            "INFO:activity_logger:> Called main(self) method - Entrance\n",
            "INFO:activity_logger:> Called main(self) - get() method - Will take some time usually 3-5min\n",
            "INFO:activity_logger:Called main(self) - line: get() method - Result:{'response time in secs': 0, 'status': True, 'code': 200, 'comment': 'url:https://api.census.gov/data/2015/cps/basic/feb?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:10&key=804d0a1a18d1de70764950c78e2a3a42d3d45e48'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function: 'get()'. Census API query took: 221.0948247909546 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> Cleaning dataAPI but removing data with no tabulate information (tabulate=0)\n",
            "INFO:activity_logger:> len(self.data4Df): 206\n",
            "INFO:activity_logger:> Called main(self) - buildingDf() method\n",
            "INFO:activity_logger:> Built Dataframe for stateiD:10, YYYYMM:2015-feb\n",
            "INFO:activity_logger:> Called main(self) - save() method - Beginning\n",
            "INFO:activity_logger:> Created CSV file: 2015-feb-MixComp.csv\n",
            "INFO:activity_logger:> Called main(self) - save() method - End\n",
            "INFO:activity_logger:> Called main(self) method - End\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prep'ing the _columns_ and _data values_ for the _df_ called **mix_composition**"
      ],
      "metadata": {
        "id": "KVty0kmNaGcQ"
      },
      "id": "KVty0kmNaGcQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert fto df"
      ],
      "metadata": {
        "id": "QIeiQKSgY-d_"
      },
      "id": "QIeiQKSgY-d_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#class Creation\n",
        "Now we have all we need for our analysis, let's try to reorganize what we build so far into a class called _MixComp_"
      ],
      "metadata": {
        "id": "5INb-cvbMhEJ"
      },
      "id": "5INb-cvbMhEJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Let's test the Class MixComp"
      ],
      "metadata": {
        "id": "9QQSyxSd8yJw"
      },
      "id": "9QQSyxSd8yJw"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}