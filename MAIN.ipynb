{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Call the API with my variables for my research"
      ],
      "metadata": {
        "id": "Nu7m15GcZfnS"
      },
      "id": "Nu7m15GcZfnS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> List of some states \"46 SD\", \"47 TN\",\"10 DE\", \"2 AK\",\"5 AR\",\"24 MD\",\"31 NE\"\n",
        "\n",
        "CBSA:\n",
        "\n",
        "\"46 SD\",\n",
        "* \"43620 Sioux Falls, SD\",\n",
        "\n",
        "\"47 TN\"\n",
        "* \"16860 Chattanooga, TN-GA\",\n",
        "* \"28940 Knoxville, TN\",\n",
        "* \"34980\": \"Nashville-Davidson--Murfreesboro--Franklin, TN\",\n",
        "* \"28700\": \"Kingsport-Bristol-Bristol, TN-VA\",\n",
        "* \"32820\": \"Memphis, TN-MS-AR\",\n",
        "* \"17300\": \"Clarksville, TN-KY\",\n",
        "* \"27740\": \"Johnson City, TN\",\n",
        "* \"17420\": \"Cleveland, TN\",\n",
        "\n",
        "\"10 DE\"\n",
        "* \"20100 Dover, DE\",\n",
        "* \"428\": \"Philadelphia-Reading-Camden, PA-NJ-DE-MD\",\n",
        "* \"41540\": \"Salisbury, MD-DE\",\n",
        "*\n",
        "* 0 city for \"2 AK\"\n",
        "\n",
        "\"5 AR\",\n",
        "* \"22900 Fort Smith, AR-OK\",\n",
        "* \"30780 Little Rock-North Little Rock-Conway, AR\",\n",
        "* \"22220 Fayetteville-Springdale-Rogers, AR-MO\",\n",
        "* \"38220 Pine Bluff, AR\",\n",
        "* \"32820 Memphis, TN-MS-AR\",\n",
        "*\n",
        "\"24 MD\",\n",
        "* \"25180\": \"Hagerstown-Martinsburg, MD-WV\",\n",
        "* \"428\": \"Philadelphia-Reading-Camden, PA-NJ-DE-MD\",\n",
        "* \"12580\": \"Baltimore-Columbia-Towson, MD\",\n",
        "* \"37980\": \"Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\",\n",
        "* \"15680\": \"California-Lexington Park, MD\",\n",
        "* \"41540\": \"Salisbury, MD-DE\","
      ],
      "metadata": {
        "id": "MiS6CIJ8WuA8"
      },
      "id": "MiS6CIJ8WuA8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CONSTANTES"
      ],
      "metadata": {
        "id": "Wf-TQOlWDpR-"
      },
      "id": "Wf-TQOlWDpR-"
    },
    {
      "cell_type": "code",
      "source": [
        "# (10) IMPORT LIBRARY\n",
        "import requests\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import json\n",
        "import logging"
      ],
      "metadata": {
        "id": "IWRGDOLjvDDP"
      },
      "id": "IWRGDOLjvDDP",
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (20) CONSTANTES\n",
        "\n",
        "#Dict of all states\n",
        "all_states = requests.get('https://api.census.gov/data/2024/cps/basic/jan/variables.json')\n",
        "states = json.loads(all_states.text)\n",
        "states_dict = states['variables']['STATE']['values']['item']\n",
        "states = [state for state in states_dict.keys()]\n",
        "\n",
        "#All year of the study\n"
      ],
      "metadata": {
        "id": "uB5R3hshb3YQ"
      },
      "id": "uB5R3hshb3YQ",
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calling the API (1st step)"
      ],
      "metadata": {
        "id": "UfTbNpBzVvFH"
      },
      "id": "UfTbNpBzVvFH"
    },
    {
      "cell_type": "code",
      "source": [
        "# (30) CLASS API and Decorator [log_activity2]\n",
        "\n",
        "def log_activity2(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # Create a logger\n",
        "        logger = logging.getLogger('activity_logger')\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        # Create a file handler and set the logging format\n",
        "        file_handler = logging.FileHandler('activity.log')\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "\n",
        "        # Add the file handler to the logger\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        # Log the activity before calling the wrapped function\n",
        "        logger.info(f'Activity: {func.__name__}')\n",
        "\n",
        "        # Call the wrapped function\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class API:\n",
        "  \"\"\"This generic class API will handle at once all request to the CPS api\n",
        "  How to?:\n",
        "  > instanciate a variable at once, then use it to browse through all variables (not data) on the Census API json file\n",
        "  > example api:    api=API()\n",
        "\n",
        "  Properties:\n",
        "  > allVars_dict (variable): a dict of all variables for each 'year' (key)\n",
        "  > examples:\n",
        "    - api.allVars_dict[2023]        * to se all the variables (dict) in 2023\n",
        "    - 'GTCBSA' in api.allVars_dict[2024].keys() *                is <GTCBSA> in 2024?\n",
        "    - api.allState_dict[2021]       * all stateID:description in year 2021\"\"\"\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    self.get()\n",
        "\n",
        "  @log_activity2\n",
        "  def get(self):\n",
        "    self.allVars_dict = {year_: year_vars for year_, year_vars in \\\n",
        "            zip(self.allYearList(), [json.loads(requests.get('https://api.census.gov/data/'+ str(year_) +'/cps/basic/jan/variables.json').text)['variables'] for year_ in self.allYearList()])}\n",
        "\n",
        "  def store(self):\n",
        "    pass\n",
        "\n",
        "  @log_activity2\n",
        "  def allStatesIdList(self, year:int=2020):\n",
        "    return list(map(int, self.allVars_dict[year]['GESTFIPS']['values']['item'].keys())) #convert in int\n",
        "\n",
        "  @log_activity2\n",
        "  def allMonthList3TLA(self):\n",
        "    month_dict = {1:\"jan\",2:\"feb\",3:\"mar\",4:\"apr\",5:\"may\",6:\"jun\",7:\"jul\",8:\"aug\",9: \"sep\",10: \"oct\",11:\"nov\",12:\"dec\"}\n",
        "    #return next(key for key, value in month_dict.items() if value == m)\n",
        "    return list(month_dict.values())\n",
        "\n",
        "  def allYearList(self):\n",
        "    return range(2010, 1+dt.now().year)\n",
        "\n",
        "  @log_activity2\n",
        "  def getVarsNameFromUrl(self, url):\n",
        "    return re.findall(r'([A-Z]+)', url)\n",
        "\n",
        "\n",
        "api=API()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AkeD9fuuu7V",
        "outputId": "85550bea-51fb-4de7-a5b8-1a78c9c00fac"
      },
      "id": "3AkeD9fuuu7V",
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Activity: get\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FileCompMix:\n",
        "  \"\"\"This class will track the which State Year and Month has already been processed\n",
        "  so we are ending up re-download the same file, knowing that we have close to 10,000 calls\n",
        "  to make with an average of 2.50 secs = ~ 7 hours in total.\n",
        "\n",
        "  Hou to?:\n",
        "  > track = FileCompMix(filename [optional])\n",
        "        - if filename contains any char then the class will generate a new fileName_%m%d-%H%M%.\n",
        "        - defaut is   ' MixCompStatus.csv '\n",
        "  > two main methods:\n",
        "        - track.record_state_of_state_year_month()   *   to store the info\n",
        "        - track.is_record_state_of_state_year_month  *   to check if elt exist already\n",
        "  \"\"\"\n",
        "  def __init__(self, fileName='') -> None:\n",
        "    if not len(fileName) == 0:\n",
        "      fileName  = dt.now().strftime(\"_%m%d-%H%M%S\")\n",
        "    self.track_file = 'MixCompStatus' + fileName + \".csv\"\n",
        "    self.set_df()\n",
        "    self.eltInFileList = [list(i) for i in self.df.values]\n",
        "\n",
        "  def set_df(self):\n",
        "    try:\n",
        "      self.df = pd.read_csv(self.track_file, header=None)\n",
        "    except Exception as e:\n",
        "      self.df = pd.DataFrame([])\n",
        "    self.hasCSVdata = self.df.shape[0]\n",
        "\n",
        "  def numberOfelement(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def record_state_of_state_year_month(self, element):\n",
        "    self.df = pd.concat([self.df, pd.DataFrame([element])], ignore_index=True)\n",
        "    #print (f'__record_state_of_state_year_month__ len: {self.df.shape[0]}')\n",
        "    self.df.to_csv(self.track_file, mode='w', header=False, index=False) #not mode='a'\n",
        "    self.hasCSVdata = True\n",
        "\n",
        "  def is_record_state_of_state_year_month(self, element):\n",
        "    if not self.hasCSVdata:\n",
        "      #print ('--------------------------------#1F File emply, so will add')\n",
        "      return False\n",
        "    else:\n",
        "      #print('______________________')\n",
        "      #print(f'------- element: {element}')\n",
        "      #print(f'------- self.eltInFileList: {self.eltInFileList}')\n",
        "      #print('______________________')\n",
        "      if (list(element) in self.eltInFileList):\n",
        "        #print ('--------------------------------#2T elt already there, so not added, skipped')\n",
        "        return True\n",
        "      #print ('--------------------------------#3F, so will add')\n",
        "      return False"
      ],
      "metadata": {
        "id": "HfEeo6dFzYCL"
      },
      "id": "HfEeo6dFzYCL",
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (40) CLASS MIXCOMP\n",
        "#Decorator to track API response time\n",
        "def track_response_time(func):\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(self, *args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        response_time = end_time - start_time\n",
        "        self.response_time = response_time  # Store in the class\n",
        "        print(f\"Function: '{func.__name__}()'. Census API query took: {response_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "#Class for unit-request (specific State, specific Year, specific Month)\n",
        "class MixComp:\n",
        "  \"\"\"\n",
        "This class will pull the Mix composition about the US population from one state.\n",
        "Code\t    Label\n",
        "tabulate  Counts of instances\n",
        "PEMNTVTY\tDemographics-native country of mother\n",
        "PEMARITL\tDemographics-marital status\n",
        "PESEX\t    Demographics-sex\n",
        "PRCITSHP\tDemographics-United States citizenship group\n",
        "GTCBSA\t  Demographics-city level\n",
        "STATE\t    FIPS STATE Code\n",
        "GTCBSA\t  Demographics-city level\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, stateID, year, month):\n",
        "      key = '&key='+'804d0a1a18d1de70764950c78e2a3a42d3d45e48'\n",
        "      self.url = 'https://api.census.gov/data/'+ str(year) +'/cps/basic/'+ month + '?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:' + str(stateID) + key\n",
        "      self.stateID = stateID\n",
        "      self.year = year\n",
        "      self.month = month\n",
        "      self.response_time = 0 # how long the API took to run on Census CPS\n",
        "      self.dataAPI = None\n",
        "      self.dataText = None\n",
        "      self.data4Df = []\n",
        "      self.df = pd.DataFrame(None) #Will contain the final df(dataframe)\n",
        "      self.initLogger()\n",
        "\n",
        "  def initLogger(self):\n",
        "      # Create a logger\n",
        "      self.logger = logging.getLogger('activity_logger')\n",
        "      self.logger.setLevel(logging.INFO)\n",
        "      # Create a file handler and set the logging format\n",
        "      file_handler = logging.FileHandler('activity.log')\n",
        "      formatter = logging.Formatter('%(asctime)s - %(levelname)s - [w86] %(message)s')\n",
        "      file_handler.setFormatter(formatter)\n",
        "      # Add the file handler to the logger\n",
        "      self.logger.addHandler(file_handler)\n",
        "\n",
        "  def __str__(self):\n",
        "      return f\"\"\"\n",
        "      Mix Composition of the US population: stateID:={self.stateID}, month={self.month}, year={self.year}\n",
        "      Dataframe head:\n",
        "         {self.df.head(3)}\"\"\"\n",
        "\n",
        "  def __repr__(self):\n",
        "      return f\"MixComp({self.stateID}, {self.year}, {self.month})\"\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.df.shape[0]\n",
        "\n",
        "  def __add__(self, other):\n",
        "      return pd.concat([self.df, other.df], axis=0)\n",
        "\n",
        "  # to convert in class\n",
        "  def checkVariable(self, year, url):\n",
        "      \"\"\"\n",
        "      this function will check if a set of variables are declared on the Census API. Using the an url as input. Vars are in ALL_CAPS\n",
        "      \"\"\"\n",
        "      api=API()\n",
        "      api.get()\n",
        "      matches = api.getVarsNameFromUrl(url)\n",
        "      cps_vars = api.allVars_dict[year].keys()\n",
        "      res = dict()\n",
        "      for var in matches:\n",
        "        res[var] = True if var in cps_vars else False\n",
        "      res['status'] = all([status for status in res.values()])\n",
        "      return res\n",
        "\n",
        "  @track_response_time\n",
        "  def get(self):\n",
        "\n",
        "      #This section will validate all variables and replace the city's with the right one if year>=2024\n",
        "#      check = self.checkVariable(self.year, self.url)\n",
        "#      print (f\"checkVariable() = {check}\")\n",
        "#      if not check['status']:\n",
        "#        print(f\"BEFORE - Variables = {check}\")\n",
        "#        if (self.year>=2024) and ('CBSA' not in check.keys()): #before 2024, City variable in 'GTCBSA', starting on 2024, City variable was 'CBSA'\n",
        "#          self.url = re.sub('GTCBSA', 'CBSA', self.url)\n",
        "#          print(f\"AFTER -  Variables = {self.checkVariable(self.year, self.url)}\\nNew URL: {self.url}\")\n",
        "#        else:\n",
        "#          raise(f\"Please check all your Census variables. Unable to find some in the API call. Variables = {check}\")\n",
        "\n",
        "      try:\n",
        "        # download the Demographics_Native_Country_Of_Mother for Mix-Compostion\n",
        "        self.dataAPI = requests.get(self.url)\n",
        "        return dict({'response time in secs': round(self.response_time,2), 'status': True if 200==self.dataAPI.status_code else False, 'code':self.dataAPI.status_code, 'comment': 'url:' + self.url})\n",
        "        None\n",
        "      except requests.exceptions.RequestException as e:\n",
        "          # Handle connection errors or HTTP errors\n",
        "          raise(\"STOP ERROR: Tools for Data Science - Semester Project: An error occurred:\\n [[[[\", e, \"]]]]\")\n",
        "\n",
        "      except AttributeError:\n",
        "          raise(\"STOP ERROR: Please check your variable name!\")\n",
        "\n",
        "  def cleaning(self):\n",
        "      self.dataText = self.dataAPI.text\n",
        "      pattern_cleaning = r'\\[0,.*?\\],?\\n?' #remove the data with no tabulate information (tabulate=0)\n",
        "      self.dataText = re.sub(pattern_cleaning, '', self.dataText)\n",
        "      pattern_cleaning = r'\\n' #remove retunr line\n",
        "      self.dataText = re.sub(pattern_cleaning, '', self.dataText)\n",
        "      self.logger.info(f'> Cleaning dataAPI but removing data with no tabulate information (tabulate=0)')\n",
        "\n",
        "  def preping(self):\n",
        "      ##Separe cols from data (numbers)\n",
        "      pattern = r'.*?(\\[\"tabulate\".*?\"GTCBSA\"\\]),([\\s\\S]*)'\n",
        "      matches = re.search(pattern, self.dataText)\n",
        "      data_cols = matches.group(1)\n",
        "      data_vals = matches.group(2)[:-1] #removing the last char \"]\" at the end.\n",
        "\n",
        "      self.data_cols = re.findall(r'\"(.*?)\"', data_cols) #Transform string_column in List_column\n",
        "\n",
        "      #Transform string_row in List of Lists then Matrix\n",
        "      rows = re.findall(r'\\[(.*?)\\]', data_vals)\n",
        "      for row in rows:\n",
        "        row_list = re.findall(r'-?\\d+(?:\\.\\d+)?', row)\n",
        "        self.data4Df.append([int(elt) for elt in row_list])\n",
        "\n",
        "      self.logger.info(f'> len(self.data4Df): {len(self.data4Df)}')\n",
        "\n",
        "  def buildingDf(self):\n",
        "      \"\"\"\n",
        "      ##Definition of variables:\n",
        "      * tabulate: represents the information related to population counts.\n",
        "      * state: column provides information about the state\n",
        "      1. PEMNTVTY Demographics-native country of mother\n",
        "      2. PEMARITL Demographics-marital status\n",
        "      3. PESEX Demographics-sex\n",
        "      4. PRCITSHP Demographics-United States citizenship group\n",
        "      5. GTCBSA Demographics-city level\n",
        "      We will understand the population composition by state about how mixed it is based on the native country of mothers,\n",
        "      marital status distribution, gender demographics, citizenship status, at the city-level characteristics.\n",
        "      This data can be used to uncover trends, patterns, and insights into the social and cultural fabric of the US population.\n",
        "      \"\"\"\n",
        "      ##Convert the result to the Df **mix_composition**\n",
        "      self.df = pd.DataFrame(self.data4Df, columns=self.data_cols)\n",
        "\n",
        "      ##Building the YYYYMM column\n",
        "      self.df['YYYYMM'] = pd.Series([dt.strptime(str(self.year)+ '-' +str(self.month), \"%Y-%b\") for _ in range(self.df.shape[0])])\n",
        "\n",
        "      self.logger.info(f'> Built Dataframe for stateiD:{self.stateID}, YYYYMM:{str(self.year)}-{str(self.month)}')\n",
        "\n",
        "  def save(self, path=''):\n",
        "      try:\n",
        "        if path == '':\n",
        "          stateID = '0'+ str(self.stateID) if len(str(self.stateID))<2 else str(self.stateID) #fixing stateID in 2 digits\n",
        "          path = str(self.year)+'-'+ str(self.month)+'-'+ str(stateID)+'-MixComp.csv'\n",
        "        r = self.df.to_csv( path, index=False)\n",
        "        self.logger.info(f'> Created CSV file: {path}')\n",
        "        return r\n",
        "      except FileNotFoundError:\n",
        "        raise (f'Check the path {path} of the file')\n",
        "\n",
        "  def build(self):\n",
        "      self.logger.info(f\"> {'v'*60}\")\n",
        "      self.logger.info(f'> Called main(self) method - Entrance')\n",
        "      self.logger.info(f'> Input Variables = stateID:{self.stateID},year:{self.year},month:{self.month}, self.url: {self.url}')\n",
        "\n",
        "      self.logger.info(f'> Called main(self) - get() method - Will take some time usually 3-5min')\n",
        "      res = self.get()\n",
        "      self.logger.info(f'Called main(self) - line: get() method - Result:{res}')\n",
        "\n",
        "      self.cleaning()\n",
        "      self.preping()\n",
        "      self.buildingDf(); self.logger.info(f'> Called main(self) - buildingDf() method')\n",
        "\n",
        "      self.logger.info(f'> Called main(self) - save() method')\n",
        "      self.save()\n",
        "\n",
        "      self.logger.info(f'> Called main(self) method - End')\n",
        "      self.logger.info(f\"> {'^'*60}\")\n"
      ],
      "metadata": {
        "id": "pkTeNx4nLZy8"
      },
      "id": "pkTeNx4nLZy8",
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (60 - 2) Going through All Months at once\n",
        "from itertools import product\n",
        "import random\n",
        "\n",
        "# Serialize (9180 in tot :( wow )\n",
        "#state_year_month = list( map( list, product(\n",
        "#                                api.allStatesIdList(),\n",
        "#                                api.allYearList(),\n",
        "#                                api.allMonthList3TLA()) ) )\n",
        "\n",
        "state_year_month = list( product(\n",
        "                                api.allStatesIdList(),\n",
        "                                api.allYearList(),\n",
        "                                api.allMonthList3TLA()) )\n",
        "\n",
        "# Shuffle\n",
        "random.shuffle(state_year_month)\n",
        "\n",
        "#logging.disable(logging.CRITICAL)\n",
        "logging.disable(logging.NOTSET)\n",
        "\n",
        "track = FileCompMix()\n",
        "\n",
        "count = {'total': len(state_year_month), 'initiallyInFile':track.numberOfelement(), 'processed': 0, 'skipped': 0}\n",
        "print ('Begin>',count)\n",
        "\n",
        "for elt in state_year_month:\n",
        "  if not track.is_record_state_of_state_year_month(elt):\n",
        "    dataA = MixComp(*elt) #(stateID, year, month)\n",
        "    dataA.build()\n",
        "\n",
        "    if count['processed']%500==0: print ('+', end='')\n",
        "    count['processed'] += 1\n",
        "    track.record_state_of_state_year_month(elt)\n",
        "  else:\n",
        "    count['skipped'] += 1\n",
        "    if count['skipped']%1000==0: print ('.', end='')\n",
        "\n",
        "print ('\\nEnd  <',count)\n",
        "print (f\"count['processed'] + count['skipped'] ?= count['total'] => [{count['processed'] + count['skipped'] } ?= {count['total']}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "OvztqiR8U0ad",
        "outputId": "c778ce66-fe08-4439-8b02-d24a4126a661"
      },
      "id": "OvztqiR8U0ad",
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Activity: allStatesIdList\n",
            "INFO:activity_logger:Activity: allMonthList3TLA\n",
            "INFO:activity_logger:> vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
            "INFO:activity_logger:> Called main(self) method - Entrance\n",
            "INFO:activity_logger:> Input Variables = self.url: https://api.census.gov/data/2023/cps/basic/jan?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:6&key=804d0a1a18d1de70764950c78e2a3a42d3d45e48, self.stateID: 6, self.year: 2023, self.month: jan\n",
            "INFO:activity_logger:> Called main(self) - get() method - Will take some time usually 3-5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin> {'total': 9180, 'initiallyInFile': 0, 'processed': 0, 'skipped': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Called main(self) - line: get() method - Result:{'response time in secs': 0, 'status': True, 'code': 200, 'comment': 'url:https://api.census.gov/data/2023/cps/basic/jan?tabulate=weight(PWSSWGT)&row+for&row+PEMNTVTY&row+PEMARITL&row+PESEX&row+PRCITSHP&row+GTCBSA&for=state:6&key=804d0a1a18d1de70764950c78e2a3a42d3d45e48'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function: 'get()'. Census API query took: 291.39223527908325 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> Cleaning dataAPI but removing data with no tabulate information (tabulate=0)\n",
            "INFO:activity_logger:> len(self.data4Df): 1947\n",
            "INFO:activity_logger:> Built Dataframe for stateiD:6, YYYYMM:2023-jan\n",
            "INFO:activity_logger:> Called main(self) - buildingDf() method\n",
            "INFO:activity_logger:> Called main(self) - save() method\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'int' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-316-e0e2cff06bd3>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_record_state_of_state_year_month\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdataA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMixComp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(stateID, year, month)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdataA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-313-120a40626c40>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'> Called main(self) - save() method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'> Called main(self) method - End'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-313-120a40626c40>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    158\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m           \u001b[0mstateID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fixing stateID in 2 digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m           \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstateID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-MixComp.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " _"
      ],
      "metadata": {
        "id": "FesYh1xAdQN7"
      },
      "id": "FesYh1xAdQN7"
    },
    {
      "cell_type": "code",
      "source": [
        "# (60) Going through All Months at once\n",
        "for year in api.allYearList():\n",
        "  for stateID in api.allStatesIdList(): #['31', '47']:\n",
        "    for month in api.allMonthList3TLA(): #['jan', 'feb']:\n",
        "      dataA = MixComp(stateID=stateID, year=year, month=month)\n",
        "      dataA.build()"
      ],
      "metadata": {
        "id": "r0MvrQ9yjoZR"
      },
      "id": "r0MvrQ9yjoZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2+2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJqBQ046hQRU",
        "outputId": "ebce75a2-5d14-4a32-a3c7-30d31089925d"
      },
      "id": "eJqBQ046hQRU",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}