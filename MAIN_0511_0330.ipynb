{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w86w86/econ8320_US-Census/blob/main/MAIN_0511_0330.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: Download all required files"
      ],
      "metadata": {
        "id": "cH2PLuseAtk2"
      },
      "id": "cH2PLuseAtk2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Call the API with my variables for my research"
      ],
      "metadata": {
        "id": "Nu7m15GcZfnS"
      },
      "id": "Nu7m15GcZfnS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> List of some states \"46 SD\", \"47 TN\",\"10 DE\", \"2 AK\",\"5 AR\",\"24 MD\",\"31 NE\"\n",
        "\n",
        "CBSA:\n",
        "\n",
        "\"46 SD\",\n",
        "* \"43620 Sioux Falls, SD\",\n",
        "\n",
        "\"47 TN\"\n",
        "* \"16860 Chattanooga, TN-GA\",\n",
        "* \"28940 Knoxville, TN\",\n",
        "* \"34980\": \"Nashville-Davidson--Murfreesboro--Franklin, TN\",\n",
        "* \"28700\": \"Kingsport-Bristol-Bristol, TN-VA\",\n",
        "* \"32820\": \"Memphis, TN-MS-AR\",\n",
        "* \"17300\": \"Clarksville, TN-KY\",\n",
        "* \"27740\": \"Johnson City, TN\",\n",
        "* \"17420\": \"Cleveland, TN\",\n",
        "\n",
        "\"10 DE\"\n",
        "* \"20100 Dover, DE\",\n",
        "* \"428\": \"Philadelphia-Reading-Camden, PA-NJ-DE-MD\",\n",
        "* \"41540\": \"Salisbury, MD-DE\",\n",
        "*\n",
        "* 0 city for \"2 AK\"\n",
        "\n",
        "\"5 AR\",\n",
        "* \"22900 Fort Smith, AR-OK\",\n",
        "* \"30780 Little Rock-North Little Rock-Conway, AR\",\n",
        "* \"22220 Fayetteville-Springdale-Rogers, AR-MO\",\n",
        "* \"38220 Pine Bluff, AR\",\n",
        "* \"32820 Memphis, TN-MS-AR\",\n",
        "*\n",
        "\"24 MD\",\n",
        "* \"25180\": \"Hagerstown-Martinsburg, MD-WV\",\n",
        "* \"428\": \"Philadelphia-Reading-Camden, PA-NJ-DE-MD\",\n",
        "* \"12580\": \"Baltimore-Columbia-Towson, MD\",\n",
        "* \"37980\": \"Philadelphia-Camden-Wilmington, PA-NJ-DE-MD\",\n",
        "* \"15680\": \"California-Lexington Park, MD\",\n",
        "* \"41540\": \"Salisbury, MD-DE\","
      ],
      "metadata": {
        "id": "MiS6CIJ8WuA8"
      },
      "id": "MiS6CIJ8WuA8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CONSTANTES"
      ],
      "metadata": {
        "id": "Wf-TQOlWDpR-"
      },
      "id": "Wf-TQOlWDpR-"
    },
    {
      "cell_type": "code",
      "source": [
        "# (10) IMPORT LIBRARY\n",
        "import requests\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import json\n",
        "import logging"
      ],
      "metadata": {
        "id": "IWRGDOLjvDDP"
      },
      "id": "IWRGDOLjvDDP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON5Q2cNbslbX",
        "outputId": "9866e2ae-a7e7-4e8e-a70e-6d5f0034ffd2"
      },
      "id": "ON5Q2cNbslbX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (20) CONSTANTES\n",
        "\n",
        "#Dict of all states\n",
        "#all_states = requests.get('https://api.census.gov/data/2024/cps/basic/jan/variables.json')\n",
        "#states = json.loads(all_states.text)\n",
        "#states_dict = states['variables']['STATE']['values']['item']\n",
        "#states = [state for state in states_dict.keys()]\n",
        "\n",
        "#All year of the study\n"
      ],
      "metadata": {
        "id": "uB5R3hshb3YQ"
      },
      "id": "uB5R3hshb3YQ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(10) CLASS API"
      ],
      "metadata": {
        "id": "UfTbNpBzVvFH"
      },
      "id": "UfTbNpBzVvFH"
    },
    {
      "cell_type": "code",
      "source": [
        "# (30) CLASS API and Decorator [log_activity2]\n",
        "\n",
        "def log_activity2(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        gdrivePath='/content/gdrive/MyDrive/project/'\n",
        "        # Create a logger\n",
        "        logger = logging.getLogger('activity_logger')\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        # Create a file handler and set the logging format\n",
        "        file_handler = logging.FileHandler(gdrivePath + 'activity.log')\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "\n",
        "        # Add the file handler to the logger\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        # Log the activity before calling the wrapped function\n",
        "        logger.info(f'Activity: {func.__name__}')\n",
        "\n",
        "        # Call the wrapped function\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class API:\n",
        "  \"\"\"This generic class API will handle at once all request to the CPS api\n",
        "  How to?:\n",
        "  > instanciate a variable at once, then use it to browse through all variables (not data) on the Census API json file\n",
        "  > example api:    api=API()\n",
        "\n",
        "  Properties:\n",
        "  > allVars_dict (variable): a dict of all variables for each 'year' (key)\n",
        "  > examples:\n",
        "    - api.allVars_dict[2023]        * to se all the variables (dict) in 2023\n",
        "    - 'GTCBSA' in api.allVars_dict[2024].keys() *                is <GTCBSA> in 2024?\n",
        "    - api.allState_dict[2021]       * all stateID:description in year 2021\"\"\"\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    self.get()\n",
        "    self.state={}\n",
        "    self.vars={ 'weight'   : {'def':'represents the information related to population counts','col':'weight'},\n",
        "        'nativity' : {'def':'Demographics-native country of mother', 'col': 'PEMNTVTY'}, #list of countries\n",
        "        'marital'  : {'def':'Demographics-marital status', 'col':'PEMARITL', 'val':{1:'Married', 2:'Not Married'}}, #1:'1,2', 2:'-1,3,4,5,6'},\n",
        "        'sex'      : {'def':'Demographics-sex', 'col':'PESEX', 'val':{1:'Male', 2:'Female'}}, #no change\n",
        "        'citiz'    : {'def':'Demographics-United States citizenship group', 'col':'PRCITSHP', 'val':{1:'Citizen', 2:'Not Citizen'}}, #1:'1,2,3,4', 2:'5'\n",
        "        'occ1'     : {'def': 'Primary Job', 'col':'PTIO1OCD'}, #list of occupations\n",
        "        'occ2'     : {'def':'Second Job', 'col':'PTIO2OCD'}, #list of occupations\n",
        "        'collegcred':{'def':'college credit completed', 'val':{1:'Four or more years college credit?', 2:'Less than 4 years'}}, #1:'5' 2: others\n",
        "        'highsch'     : {'def':'Second Job', 'col':'PEDIPGED', 'val':{1:'High School GED', 2:'No High School GED'}},  # 1:'1,2', 2:'-1'\n",
        "        'city'     : {'def':'Demographics-city level', 'col':'GTCBSA'},\n",
        "        'state'    : {'def':'Sate', 'col':'', 'val': json.loads(requests.get('https://api.census.gov/data/2024/cps/basic/jan/variables.json').text)['variables']['STATE']['values']['item']}}\n",
        "\n",
        "\n",
        "  def get(self):\n",
        "    #TEST\n",
        "    #abc = requests.get('https://api.census.gov/data/2023/cps/basic/jan/variables.json')\n",
        "    #print(abc)\n",
        "    self.allVars_dict = {year_: year_vars for year_, year_vars in \\\n",
        "            zip(self.allYearList(), [json.loads(requests.get('https://api.census.gov/data/'+ str(year_) +'/cps/basic/jan/variables.json').text)['variables'] for year_ in self.allYearList()])}\n",
        "\n",
        "  @log_activity2\n",
        "  def allStatesIdList(self, year:int=2010):\n",
        "    return list(map(int, self.allVars_dict[year]['GESTFIPS']['values']['item'].keys())) #convert in int\n",
        "\n",
        "  @log_activity2\n",
        "  def allMonthList3TLA(self, specific_month=None):\n",
        "    month_dict = {1:\"jan\",2:\"feb\",3:\"mar\",4:\"apr\",5:\"may\",6:\"jun\",7:\"jul\",8:\"aug\",9: \"sep\",10: \"oct\",11:\"nov\",12:\"dec\"}\n",
        "    #return next(key for key, value in month_dict.items() if value == m)\n",
        "    if specific_month is None:\n",
        "      return list(month_dict.values())\n",
        "    else:\n",
        "      return [specific_month]\n",
        "\n",
        "  def allYearList(self):\n",
        "    return range(2010, 1+dt.now().year)\n",
        "\n",
        "  @log_activity2\n",
        "  def getVarsNameFromUrl(self, url):\n",
        "    return re.findall(r'([A-Z]+)', url)\n",
        "\n",
        "  def id_to_stateName(self,id):\n",
        "    return self.vars['state']['val'][str(id)]\n",
        "\n",
        "api=API()"
      ],
      "metadata": {
        "id": "3AkeD9fuuu7V",
        "collapsed": true
      },
      "id": "3AkeD9fuuu7V",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "api.vars['sex']['val'][i]\n",
        "api.allMonthList3TLA('jun')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wbhpo2ILH5Re",
        "outputId": "9c166348-1228-49da-8bc3-133932803e26"
      },
      "id": "Wbhpo2ILH5Re",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Activity: allMonthList3TLA\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jun']"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(20) CLASS FileCompMix:"
      ],
      "metadata": {
        "id": "ecfQhoBJw4Me"
      },
      "id": "ecfQhoBJw4Me"
    },
    {
      "cell_type": "code",
      "source": [
        "class FileCompMix:\n",
        "  \"\"\"This class will track the which State Year and Month has already been processed\n",
        "  so we are ending up re-download the same file, knowing that we have close to 10,000 calls\n",
        "  to make with an average of 2.50 secs = ~ 7 hours in total.\n",
        "\n",
        "  Hou to?:\n",
        "  > track = FileCompMix(filename [optional])\n",
        "        - if filename contains any char then the class will generate a new fileName_%m%d-%H%M%.\n",
        "        - defaut is   ' MixCompStatus.csv '\n",
        "  > two main methods:\n",
        "        - track.record_state_of_state_year_month()   *   to store the info\n",
        "        - track.is_record_state_of_state_year_month  *   to check if elt exist already\n",
        "  \"\"\"\n",
        "  def __init__(self, fileName='', gdrivePath='/content/gdrive/MyDrive/project/') -> None:\n",
        "    if not len(fileName) == 0:\n",
        "      fileName  = dt.now().strftime(\"_%m%d-%H%M%S\")\n",
        "    self.gdrivePath = gdrivePath\n",
        "    self.track_file = self.gdrivePath + 'MixCompStatus' + fileName + \".csv\"\n",
        "    self.set_df()\n",
        "    self.eltInFileList = [list(i) for i in self.df.values]\n",
        "\n",
        "\n",
        "  def set_df(self):\n",
        "    \"\"\"Read the NTFS file, and load it to a df so we can browse in in and download what has not been yet download\n",
        "    \"\"\"\n",
        "    try:\n",
        "      self.df = pd.read_csv(self.track_file, header=None)\n",
        "    except Exception as e:\n",
        "      self.df = pd.DataFrame([])\n",
        "    self.hasCSVdata = self.df.shape[0]\n",
        "\n",
        "  def numberOfelement(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def record_state_of_state_year_month(self, element):\n",
        "    self.df = pd.concat([self.df, pd.DataFrame([element])], ignore_index=True)\n",
        "    #print (f'__record_state_of_state_year_month__ len: {self.df.shape[0]}')\n",
        "    self.df.to_csv(self.track_file, mode='w', header=False, index=False) #not mode='a'\n",
        "    self.hasCSVdata = True\n",
        "\n",
        "  def is_record_state_of_state_year_month(self, element):\n",
        "    if not self.hasCSVdata:\n",
        "      #print ('--------------------------------#1F File emply, so will add')\n",
        "      return False\n",
        "    else:\n",
        "      if (list(element) in self.eltInFileList):\n",
        "        #print ('--------------------------------#2T elt already there, so not added, skipped')\n",
        "        return True\n",
        "      #print ('--------------------------------#3F, so will add')\n",
        "      return False"
      ],
      "metadata": {
        "id": "HfEeo6dFzYCL"
      },
      "id": "HfEeo6dFzYCL",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(40) CLASS MIXCOMP"
      ],
      "metadata": {
        "id": "nZpi3PtBwkHG"
      },
      "id": "nZpi3PtBwkHG"
    },
    {
      "cell_type": "code",
      "source": [
        "# (40) CLASS MIXCOMP\n",
        "#Decorator to track API response time\n",
        "def track_response_time(func):\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(self, *args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        response_time = end_time - start_time\n",
        "        self.response_time = response_time  # Store in the class\n",
        "        print(f\"Function: '{func.__name__}()'. Census API query took: {response_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "#Class for unit-request (All State, specific Year, specific Month)\n",
        "class MixComp:\n",
        "  \"\"\"\n",
        "This class will pull the Mix composition about the US population from one state.\n",
        "Code\t    Label\n",
        "tabulate  Counts of instances\n",
        "PEMNTVTY\tDemographics-native country of mother\n",
        "PEMARITL\tDemographics-marital status\n",
        "PESEX\t    Demographics-sex\n",
        "PRCITSHP\tDemographics-United States citizenship group\n",
        "GTCBSA\t  Demographics-city level\n",
        "STATE\t    FIPS STATE Code\n",
        "GTCBSA\t  Demographics-city level\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, year, month):\n",
        "      #key = '&key='+'804d0a1a18d1de70764950c78e2a3a42d3d45e48' #w86\n",
        "      key = '&key='+'a24a131b4da25b83199bdc7202fcab553b9e2983' #luos\n",
        "      self.url = 'https://api.census.gov/data/'+str(year)+'/cps/basic/'+month+'?get=PWSSWGT,PEMNTVTY,PEMARITL,PESEX,PRCITSHP,PTIO1OCD,PTIO2OCD,PECYC,PEDIPGED,GTCBSA&for=state:*'+ key\n",
        "      self.gdrivePath='/content/gdrive/MyDrive/project/'\n",
        "      self.activityLog = self.gdrivePath + 'activity.log'\n",
        "      self.year = year\n",
        "      self.month = month\n",
        "      self.response_time = 0 # how long the API took to run on Census CPS\n",
        "      self.dataAPI = None\n",
        "      self.dataText = None\n",
        "      self.data4Df = []\n",
        "      self.df = pd.DataFrame(None) #Will contain the final df(dataframe)\n",
        "      self.initLogger()\n",
        "\n",
        "  def initLogger(self):\n",
        "      # Create a logger\n",
        "      self.logger = logging.getLogger('activity_logger')\n",
        "      self.logger.setLevel(logging.INFO)\n",
        "      # Create a file handler and set the logging format\n",
        "      file_handler = logging.FileHandler(self.activityLog)\n",
        "      formatter = logging.Formatter('%(asctime)s - %(levelname)s - [w86] %(message)s')\n",
        "      file_handler.setFormatter(formatter)\n",
        "      # Add the file handler to the logger\n",
        "      self.logger.addHandler(file_handler)\n",
        "\n",
        "  def __str__(self):\n",
        "      return f\"\"\"\n",
        "      Mix Composition of the US population: month={self.month}, year={self.year}\n",
        "      Dataframe head:\n",
        "         {self.df.head(3)}\"\"\"\n",
        "\n",
        "  def __repr__(self):\n",
        "      return f\"MixComp({self.year}, {self.month})\"\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.df.shape[0]\n",
        "\n",
        "  def __add__(self, other):\n",
        "      return pd.concat([self.df, other.df], axis=0)\n",
        "\n",
        "  # to convert in class\n",
        "  def checkVariable(self, year, url):\n",
        "      \"\"\"This function will check if a set of variables are declared on the Census API. Using the an url as input. Vars are in ALL_CAPS\n",
        "      \"\"\"\n",
        "      api=API()\n",
        "      api.get()\n",
        "      matches = api.getVarsNameFromUrl(url)\n",
        "      cps_vars = api.allVars_dict[year].keys()\n",
        "      res = dict()\n",
        "      for var in matches:\n",
        "        res[var] = True if var in cps_vars else False\n",
        "      res['status'] = all([status for status in res.values()])\n",
        "      return res\n",
        "\n",
        "  @track_response_time\n",
        "  def get(self):\n",
        "      #This section will validate all variables and replace the city's with the right one if year>=2024 (GTCBSA->CBSA)\n",
        "      check = self.checkVariable(self.year, self.url)\n",
        "      print (f\"checkVariable() = {check}\")\n",
        "      if not check['status']:\n",
        "        self.logger.info(f\"> Class MixComp: / get() / BEFORE - Variables = {check}\")\n",
        "        if (self.year>=2024) and ('CBSA' not in check.keys()): #before 2024, City variable in 'GTCBSA', starting on 2024, City variable was 'CBSA'\n",
        "          self.url = re.sub('GTCBSA', 'CBSA', self.url)\n",
        "          self.logger.info(f\"Class MixComp: / get() / > AFTER -  Variables = {self.checkVariable(self.year, self.url)}\\nNew URL: {self.url}\")\n",
        "        else:\n",
        "          self.logger.info(f\"Class MixComp: / get() / > Please check all your Census variables. Unable to find some in the API call. Variables = {check}\")\n",
        "\n",
        "      try:\n",
        "        # download the Demographics_Native_Country_Of_Mother for Mix-Compostion\n",
        "        self.dataAPI = requests.get(self.url)\n",
        "        res = dict({'response time in secs': round(self.response_time,2), 'status': True if 200==self.dataAPI.status_code else False, 'code':self.dataAPI.status_code, 'comment': 'url:' + self.url})\n",
        "        self.logger.info(f'Class MixComp: / get() / > Return dict: [[[[ {res} ]]]]')\n",
        "        return res\n",
        "\n",
        "      except requests.exceptions.RequestException as e:\n",
        "          # Handle connection errors or HTTP errors\n",
        "          #raise(\"STOP ERROR: Tools for Data Science - Semester Project: An error occurred:\\n [[[[\", e, \"]]]]\")\n",
        "          self.logger.info(f'Class MixComp: / get() / > STOP ERROR: Tools for Data Science - Semester Project: An error occurred:\\n [[[[ {e} ]]]]')\n",
        "          self.logger.info(f'Class MixComp: / get() / > Skipped !!')\n",
        "      except AttributeError:\n",
        "          self.logger.info(f'Class MixComp: / get() / > STOP ERROR: Please check your variable name!')\n",
        "\n",
        "  def buildingDf(self):\n",
        "      \"\"\"\n",
        "      ##Definition of variables:\n",
        "      1. weight     represents the information related to population counts.\n",
        "      2. nativity   column provides information about the state\n",
        "      1. PEMNTVTY   Demographics-native country of mother\n",
        "      3. marital    Demographics-marital status\n",
        "      4. sex        Demographics-sex\n",
        "      5. citiz      Demographics-United States citizenship group\n",
        "      6. occ1       Primary Job\n",
        "      7. occ2       Second Job\n",
        "      8. collegcred college credit completed\n",
        "      5. city       Demographics-city level\n",
        "      We will understand the population composition by state about how mixed it is based on the native country of mothers,\n",
        "      marital status distribution, gender demographics, citizenship status, at the city-level characteristics.\n",
        "      This data can be used to uncover trends, patterns, and insights into the social and cultural fabric of the US population.\n",
        "      \"\"\"\n",
        "      ##Build df and Renmane Df Columns for easy reading.\n",
        "      self.df = pd.DataFrame(list(json.loads(self.dataAPI.text))[1:],columns = ['weight', 'nativity', 'marital', 'sex', 'citiz', 'occ1','occ2', 'collegcred','highsch', 'city', 'state'])\n",
        "      ##Remove unknown City ID city==0\n",
        "      self.df = self.df[self.df['city']!='0']\n",
        "      self.logger.info(f'Class MixComp: / buildingDf > Remove unknown City ID, Build df and Renmane Df Columns for easy reading.')\n",
        "      ##Building the YYYYMM column\n",
        "      self.df['YYYYMM'] = dt.strptime(str(self.year)+ '-' +str(self.month), \"%Y-%b\")\n",
        "      self.logger.info(f'Class MixComp: / buildingDf > Built Dataframe for YYYYMM:{str(self.year)}-{str(self.month)}')\n",
        "      #convert column in true type 'citiz', 'occ1','occ2', 'collegcred','highsch', 'city', 'state'])\n",
        "      self.df['weight'] = self.df['weight'].astype(float)\n",
        "      self.df['nativity'] = self.df['nativity'].astype(int)\n",
        "      self.df['marital'] = self.df['marital'].astype(int)\n",
        "      self.df['sex'] = self.df['sex'].astype(int)\n",
        "      self.df['citiz'] = self.df['citiz'].astype(int)\n",
        "      self.df['occ1'] = self.df['occ1'].astype(int)\n",
        "      self.df['occ2'] = self.df['occ2'].astype(int)\n",
        "      self.df['collegcred'] = self.df['collegcred'].astype(int)\n",
        "      self.df['highsch'] = self.df['highsch'].astype(int)\n",
        "      self.df['city'] = self.df['city'].astype(int)\n",
        "      self.df['state'] = self.df['state'].astype(int)\n",
        "      #convert content with relevant information\n",
        "      self.df['marital'] = self.df['marital'].apply(lambda x: 1 if x in [1,2] else 2)\n",
        "      self.df['citiz'] = self.df['citiz'].apply(lambda x: 1 if x in [1,2,3,4] else 2)\n",
        "      self.df['collegcred'] = self.df['collegcred'].apply(lambda x: 1 if x in [5] else 2)\n",
        "      self.df['highsch'] = self.df['highsch'].apply(lambda x: 1 if x in [1,2] else 2)\n",
        "\n",
        "  def save(self, file=''):\n",
        "      try:\n",
        "        if file == '':\n",
        "          file = str(self.year)+'-'+ str(self.month)+'-MixComp.csv'\n",
        "        r = self.df.to_csv( self.gdrivePath + file, index=False)\n",
        "        self.logger.info(f'Class MixComp: / save > Created CSV file: {file}')\n",
        "        return r\n",
        "      except FileNotFoundError:\n",
        "        raise (f'Check the path {file} of the file')\n",
        "        self.logger.info(f'Class MixComp: / save > Check the path {file} of the file')\n",
        "        self.logger.info(f'Class MixComp: / save > Skipped {file} creation')\n",
        "\n",
        "  def main(self):\n",
        "      self.logger.info(f\"> {'v'*30} year:{self.year},month:{self.month} {'v'*30}\")\n",
        "      self.logger.info(f'Class MixComp: / main >  method - Entrance')\n",
        "      self.logger.info(f'>Class MixComp: / main > get() method')\n",
        "\n",
        "      url_call = self.get()\n",
        "      self.logger.info(f'Class MixComp: / main - line: get() method - Result:{url_call}')\n",
        "\n",
        "      try:\n",
        "        if url_call['status']:\n",
        "          self.buildingDf();  self.logger.info(f'Class MixComp: / main > URL found (200), now Creating the df')\n",
        "          self.save();        self.logger.info(f'Class MixComp: / main > save() method')\n",
        "        else:\n",
        "          self.logger.info(f\"Class MixComp: / main > Error during URL call, Code return: {url_call['code']}, Skipped !!\")\n",
        "      except Exception as e:\n",
        "        self.logger.info(f\"Class MixComp: / main > Error during URL call, Code return was undefinied, !! Please also check the API KEY!! Skipped !!\")\n",
        "      self.logger.info(f'Class MixComp: / main > Called main(self) method - End')\n",
        "      self.logger.info(f\"> {'^'*90}\")\n",
        "      return url_call['status']\n"
      ],
      "metadata": {
        "id": "pkTeNx4nLZy8"
      },
      "id": "pkTeNx4nLZy8",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(60) CORE #1 (this section will create individual files: yyyy-mm-MixComp.csv)"
      ],
      "metadata": {
        "id": "FaDs85AMwyIy"
      },
      "id": "FaDs85AMwyIy"
    },
    {
      "cell_type": "code",
      "source": [
        "## (60 - 1) Going through All Months at once\n",
        "track = FileCompMix()\n",
        "count = {'initiallyInFile': track.numberOfelement(), 'processed': 0, 'skipped': 0}\n",
        "print ('Begin>',count)\n",
        "\n",
        "for year in api.allYearList():\n",
        "  for month in api.allMonthList3TLA(): #['jan', 'feb']:\n",
        "    elt = [year,month]\n",
        "    if not track.is_record_state_of_state_year_month(elt):\n",
        "      dataA = MixComp(*elt) #(year, month)\n",
        "\n",
        "      result = dataA.main()\n",
        "\n",
        "      if count['processed']%500==0: print ('+', end='')\n",
        "      count['processed'] += 1\n",
        "      if result: track.record_state_of_state_year_month(elt)\n",
        "    else:\n",
        "      count['skipped'] += 1\n",
        "      if count['skipped']%1000==0: print ('.', end='')\n",
        "\n",
        "print ('\\nEnd  <',count)\n",
        "print (f\"count['processed']: {count['processed']},count['skipped']: {count['skipped']}\")"
      ],
      "metadata": {
        "id": "l6wJsLXwmypE",
        "outputId": "bb7342ec-b67f-4045-8fe9-e835794afda2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "collapsed": true
      },
      "id": "l6wJsLXwmypE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Activity: allMonthList3TLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin> {'initiallyInFile': 1, 'processed': 0, 'skipped': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:> vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv year:2010,month:feb vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
            "INFO:activity_logger:Class MixComp: / main >  method - Entrance\n",
            "INFO:activity_logger:>Class MixComp: / main > get() method\n",
            "INFO:activity_logger:Activity: getVarsNameFromUrl\n",
            "INFO:activity_logger:> Class MixComp: / get() / BEFORE - Variables = {'PWSSWGT': True, 'PEMNTVTY': True, 'PEMARITL': True, 'PESEX': True, 'PRCITSHP': True, 'PTIO': False, 'OCD': False, 'PECYC': True, 'PEDIPGED': True, 'GTCBSA': True, 'status': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkVariable() = {'PWSSWGT': True, 'PEMNTVTY': True, 'PEMARITL': True, 'PESEX': True, 'PRCITSHP': True, 'PTIO': False, 'OCD': False, 'PECYC': True, 'PEDIPGED': True, 'GTCBSA': True, 'status': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Class MixComp: / get() / > Please check all your Census variables. Unable to find some in the API call. Variables = {'PWSSWGT': True, 'PEMNTVTY': True, 'PEMARITL': True, 'PESEX': True, 'PRCITSHP': True, 'PTIO': False, 'OCD': False, 'PECYC': True, 'PEDIPGED': True, 'GTCBSA': True, 'status': False}\n",
            "INFO:activity_logger:Class MixComp: / get() / > Return dict: [[[[ {'response time in secs': 0, 'status': True, 'code': 200, 'comment': 'url:https://api.census.gov/data/2010/cps/basic/feb?get=PWSSWGT,PEMNTVTY,PEMARITL,PESEX,PRCITSHP,PTIO1OCD,PTIO2OCD,PECYC,PEDIPGED,GTCBSA&for=state:*&key=a24a131b4da25b83199bdc7202fcab553b9e2983'} ]]]]\n",
            "INFO:activity_logger:Class MixComp: / main - line: get() method - Result:{'response time in secs': 0, 'status': True, 'code': 200, 'comment': 'url:https://api.census.gov/data/2010/cps/basic/feb?get=PWSSWGT,PEMNTVTY,PEMARITL,PESEX,PRCITSHP,PTIO1OCD,PTIO2OCD,PECYC,PEDIPGED,GTCBSA&for=state:*&key=a24a131b4da25b83199bdc7202fcab553b9e2983'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function: 'get()'. Census API query took: 14.372019052505493 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Class MixComp: / buildingDf > Remove unknown City ID, Build df and Renmane Df Columns for easy reading.\n",
            "INFO:activity_logger:Class MixComp: / buildingDf > Built Dataframe for YYYYMM:2010-feb\n",
            "INFO:activity_logger:Class MixComp: / main > URL found (200), now Creating the df\n",
            "INFO:activity_logger:Class MixComp: / save > Created CSV file: 2010-feb-MixComp.csv\n",
            "INFO:activity_logger:Class MixComp: / main > save() method\n",
            "INFO:activity_logger:Class MixComp: / main > Called main(self) method - End\n",
            "INFO:activity_logger:> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "INFO:activity_logger:> vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv year:2010,month:mar vvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:activity_logger:Class MixComp: / main >  method - Entrance\n",
            "INFO:activity_logger:>Class MixComp: / main > get() method\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-90135fcc3348>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mdataA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMixComp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(year, month)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-937abc8acfb3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'>Class MixComp: / main > get() method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0murl_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Class MixComp: / main - line: get() method - Result:{url_call}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-937abc8acfb3>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mresponse_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-937abc8acfb3>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0;31m#This section will validate all variables and replace the city's with the right one if year>=2024 (GTCBSA->CBSA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"checkVariable() = {check}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-937abc8acfb3>\u001b[0m in \u001b[0;36mcheckVariable\u001b[0;34m(self, year, url)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \"\"\"\n\u001b[1;32m     75\u001b[0m       \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m       \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetVarsNameFromUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0mcps_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallVars_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-ffe49dccb19b>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#print(abc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     self.allVars_dict = {year_: year_vars for year_, year_vars in \\\n\u001b[0;32m---> 48\u001b[0;31m             zip(self.allYearList(), [json.loads(requests.get('https://api.census.gov/data/'+ str(year_) +'/cps/basic/jan/variables.json').text)['variables'] for year_ in self.allYearList()])}\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mlog_activity2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-ffe49dccb19b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#print(abc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     self.allVars_dict = {year_: year_vars for year_, year_vars in \\\n\u001b[0;32m---> 48\u001b[0;31m             zip(self.allYearList(), [json.loads(requests.get('https://api.census.gov/data/'+ str(year_) +'/cps/basic/jan/variables.json').text)['variables'] for year_ in self.allYearList()])}\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mlog_activity2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(70) CORE #2 Merging to one (this section will create individual files: yyyy-Merged.csv)"
      ],
      "metadata": {
        "id": "7HyvZXuubh66"
      },
      "id": "7HyvZXuubh66"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import pandas  as pd\n",
        "\n",
        "mergedJSON = {}\n",
        "mergedJSON['merged'] = '/content/gdrive/MyDrive/mergedByYear/'\n",
        "mergedJSON['unMergedPath'] = '/content/gdrive/MyDrive/project/'\n",
        "mergedJSON['files'] ={}\n",
        "mergedJSON['yearly'] = {}\n",
        "\n",
        "def merge():\n",
        "    \"\"\"Will transfer all done file in a folder \"mergedByYear\"\n",
        "    \"\"\"\n",
        "    filenameList = os.listdir(mergedJSON['unMergedPath'])\n",
        "    filenameList = [file for file in filenameList if re.match(r'^\\d{4}', file)]\n",
        "\n",
        "    print (filenameList)\n",
        "    \"Example: 2010-apr-MixComp.csv\"\n",
        "\n",
        "    for file in filenameList:\n",
        "      year = file.split('-')[0]\n",
        "      if (int(year)>=2010) and (int(year)<=2024):\n",
        "        if year not in mergedJSON['yearly']:\n",
        "          mergedJSON['yearly'][year]=[]\n",
        "        df = pd.read_csv(mergedJSON['unMergedPath'] + file)\n",
        "        mergedJSON['yearly'][year].append(df)\n",
        "\n",
        "    mergedJSON['fused'] = {}\n",
        "    for year, dfs in mergedJSON['yearly'].items():\n",
        "      mergedJSON['fused'][year] = pd.concat(dfs)\n",
        "\n",
        "    for year, df in mergedJSON['fused'].items():\n",
        "      path = mergedJSON['merged']\n",
        "      df.to_csv(f'{path}{year}_merged.csv', index=False)\n",
        "\n",
        "merge()"
      ],
      "metadata": {
        "id": "Oh8btjJvbhdL"
      },
      "id": "Oh8btjJvbhdL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: Graphics (Streamlit, ...)"
      ],
      "metadata": {
        "id": "1nxK_syeA96T"
      },
      "id": "1nxK_syeA96T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Attempt to display graph"
      ],
      "metadata": {
        "id": "l_wWttWGOLFP"
      },
      "id": "l_wWttWGOLFP"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzUB_E2ZGdYv",
        "outputId": "66ef8631-e8e3-4976-c8f2-e23401323a44"
      },
      "id": "LzUB_E2ZGdYv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "RmbixXFnNhPa",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b0ef7a-2dd4-48eb-84c6-ef66c0762ed5"
      },
      "id": "RmbixXFnNhPa",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.34.0 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st"
      ],
      "metadata": {
        "id": "NXqiE8cmN0ab"
      },
      "id": "NXqiE8cmN0ab",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.write(\"Hello world...\")"
      ],
      "metadata": {
        "id": "ZAQ87Z5IN37B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5c45bb-6524-43cf-a5d3-e88d05bb934b"
      },
      "id": "ZAQ87Z5IN37B",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-11 04:48:40.255 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py"
      ],
      "metadata": {
        "id": "SI9-hLZlN4nC",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a7b9d2-4a9f-463a-e51c-7fc2a0dde5c4"
      },
      "id": "SI9-hLZlN4nC",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.206.124:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function shutdown at 0x79b908fcf880>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 2182, in shutdown\n",
            "    h.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1083, in flush\n",
            "    if self.stream and hasattr(self.stream, \"flush\"):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/web/bootstrap.py\", line 55, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/web/server/server.py\", line 404, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/runtime.py\", line 327, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 798, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 515, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, regex as re, pandas as pd\n",
        "mergedJSON = {}\n",
        "mergedJSON['merged'] = '/content/gdrive/MyDrive/mergedByYear/'\n",
        "\n",
        "filenameList = os.listdir(mergedJSON['merged'])\n",
        "filenameList = [file for file in filenameList if re.match(r'^\\d{4}', file)]\n",
        "filenameList = iter(filenameList)\n",
        "file = next(filenameList)\n",
        "print (f'file:{file}')\n",
        "\n",
        "df = pd.read_csv (mergedJSON['merged'] + file)\n",
        "print (df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtl75cJt5qmh",
        "outputId": "d854144a-bc1f-4703-9a4d-8646426a453e"
      },
      "id": "mtl75cJt5qmh",
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file:2010_merged.csv\n",
            "Index(['weight', 'nativity', 'marital', 'sex', 'citiz', 'occ1', 'occ2',\n",
            "       'collegcred', 'highsch', 'city', 'state', 'YYYYMM'],\n",
            "      dtype='object')\n",
            "Cleaning / df_Len1:1185122, df_Len2:1185122, df_Len3:1185122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.unique(df['highsch'])\n",
        "df[df['highsch']==3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "5rswxoE7AFMb",
        "outputId": "26722345-f077-4f61-c201-d7783798ae88"
      },
      "id": "5rswxoE7AFMb",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [weight, nativity, marital, sex, citiz, occ1, occ2, collegcred, highsch, city, state, YYYYMM]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32a3e331-b2d9-4626-80d7-f53844de917e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weight</th>\n",
              "      <th>nativity</th>\n",
              "      <th>marital</th>\n",
              "      <th>sex</th>\n",
              "      <th>citiz</th>\n",
              "      <th>occ1</th>\n",
              "      <th>occ2</th>\n",
              "      <th>collegcred</th>\n",
              "      <th>highsch</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>YYYYMM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a3e331-b2d9-4626-80d7-f53844de917e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32a3e331-b2d9-4626-80d7-f53844de917e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32a3e331-b2d9-4626-80d7-f53844de917e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby(['state', 'nativity', 'marital', 'sex', 'citiz', 'occ1', 'occ2',\n",
        "                      'collegcred', 'highsch', 'city', 'YYYYMM'])['weight'].sum().reset_index()\n",
        "\n",
        "\n",
        "grouped.to_csv('2010_Merged.csv')\n",
        "\n",
        "#grouped [grouped['state']==31]\n",
        "\n",
        "#print (df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_A3Vjb13JoCf"
      },
      "id": "_A3Vjb13JoCf",
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "choose_year     = pd.to_datetime(grouped['YYYYMM']).dt.year==2010\n",
        "choose_state    = grouped['state']==10\n",
        "choose_month    = pd.to_datetime(grouped['YYYYMM']).dt.month==5\n",
        "choose_marital  = None\n",
        "choose_citiz    = None\n",
        "choose_collegcred = None\n",
        "choose_highsch  = None\n",
        "\"\"\"\n",
        "choose_year     = None\n",
        "#choose_year     = pd.to_datetime(grouped['YYYYMM']).dt.year==2010\n",
        "choose_state    = None\n",
        "#choose_state    = grouped['state']==20\n",
        "choose_month    = None\n",
        "#choose_month    = pd.to_datetime(grouped['YYYYMM']).dt.month==5\n",
        "choose_marital  = None\n",
        "#choose_marital  = grouped['marital']== 1\n",
        "choose_citiz    = None\n",
        "#choose_citiz    = grouped['citiz']== 1\n",
        "choose_collegcred = None\n",
        "#choose_collegcred = grouped['collegcred']== 1\n",
        "choose_highsch  = None\n",
        "#choose_highsch  = grouped['highsch']== 2\n",
        "\n",
        "condition = None\n",
        "\n",
        "if choose_year is not None:\n",
        "  if condition is None: condition = choose_year\n",
        "  else: condition &= choose_year\n",
        "\n",
        "if choose_state is not None:\n",
        "  if condition is None: condition = choose_state\n",
        "  else: condition &= choose_state\n",
        "\n",
        "if choose_month is not None:\n",
        "  if condition is None: condition = choose_month\n",
        "  else: condition &= choose_month\n",
        "\n",
        "if choose_marital is not None:\n",
        "  if condition is None: condition = choose_marital\n",
        "  else: condition &= choose_marital\n",
        "\n",
        "if choose_citiz is not None:\n",
        "  if condition is None: condition = choose_citiz\n",
        "  else: condition &= choose_citiz\n",
        "\n",
        "if choose_collegcred is not None:\n",
        "  if condition is None: condition = choose_collegcred\n",
        "  else: condition &= choose_collegcred\n",
        "\n",
        "\n",
        "if choose_highsch is not None:\n",
        "  if condition is None: condition = choose_highsch\n",
        "  else: condition &= choose_highsch\n",
        "\n",
        "#if none selected display everything\n",
        "if condition is None: condition=pd.Series([True] * len(grouped))\n",
        "\n",
        "#g2 = grouped [(pd.to_datetime(grouped['YYYYMM']).dt.month==5) & (grouped['state']==10)]\n",
        "g2 = grouped [condition]\n",
        "#Display the 7 highest population\n",
        "g2 = g2.groupby(['state'])['weight'].sum().reset_index().sort_values(by='weight', ascending=False).head(7)\n",
        "g2['state'] = g2['state'].apply(lambda x: api.id_to_stateName(x))\n",
        "print (g2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNnjsKD4PoD0",
        "outputId": "f9782678-f573-4ed7-d72b-871d4c6346b8"
      },
      "id": "xNnjsKD4PoD0",
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   state        weight\n",
            "3     CA  4.330356e+08\n",
            "42    TX  2.551432e+08\n",
            "31    NY  2.133840e+08\n",
            "8     FL  2.101187e+08\n",
            "12    IL  1.353728e+08\n",
            "37    PA  1.213336e+08\n",
            "29    NJ  1.036364e+08\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Nu7m15GcZfnS",
        "Wf-TQOlWDpR-",
        "ecfQhoBJw4Me"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}