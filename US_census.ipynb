{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: Download all required files"
      ],
      "metadata": {
        "id": "cH2PLuseAtk2"
      },
      "id": "cH2PLuseAtk2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LIBRARIES, CONSTANTES"
      ],
      "metadata": {
        "id": "Wf-TQOlWDpR-"
      },
      "id": "Wf-TQOlWDpR-"
    },
    {
      "cell_type": "code",
      "source": [
        "# (10) IMPORT LIBRARY\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import json\n",
        "import logging"
      ],
      "metadata": {
        "id": "IWRGDOLjvDDP"
      },
      "id": "IWRGDOLjvDDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (20) CONSTANTES\n",
        "\n",
        "#Dict of all states\n",
        "#all_states = requests.get('https://api.census.gov/data/2024/cps/basic/jan/variables.json')\n",
        "#states = json.loads(all_states.text)\n",
        "#states_dict = states['variables']['STATE']['values']['item']\n",
        "#states = [state for state in states_dict.keys()]\n",
        "\n",
        "#All year of the study\n"
      ],
      "metadata": {
        "id": "uB5R3hshb3YQ"
      },
      "id": "uB5R3hshb3YQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(10) CLASS API"
      ],
      "metadata": {
        "id": "UfTbNpBzVvFH"
      },
      "id": "UfTbNpBzVvFH"
    },
    {
      "cell_type": "code",
      "source": [
        "# (30) CLASS API and Decorator [log_activity2]\n",
        "\n",
        "def log_activity2(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # Create a logger\n",
        "        logger = logging.getLogger('activity_logger')\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        # Create a file handler and set the logging format\n",
        "        file_handler = logging.FileHandler('activity.log')\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "\n",
        "        # Add the file handler to the logger\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        # Log the activity before calling the wrapped function\n",
        "        logger.info(f'Activity: {func.__name__}')\n",
        "\n",
        "        # Call the wrapped function\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class API:\n",
        "  \"\"\"This generic class API will handle at once all request to the CPS api\n",
        "  How to?:\n",
        "  > instanciate a variable at once, then use it to browse through all variables (not data) on the Census API json file\n",
        "  > example api:    api=API()\n",
        "\n",
        "  Properties:\n",
        "  > allVars_dict (variable): a dict of all variables for each 'year' (key)\n",
        "  > examples:\n",
        "    - api.allVars_dict[2023]        * to se all the variables (dict) in 2023\n",
        "    - 'GTCBSA' in api.allVars_dict[2024].keys() *                is <GTCBSA> in 2024?\n",
        "    - api.allState_dict[2021]       * all stateID:description in year 2021\"\"\"\n",
        "\n",
        "  def __init__(self, env='gdrive') -> None:\n",
        "    \"\"\"The var 'env' is to define where the program is running.\n",
        "    Two possible values:\n",
        "     - 'gdrive' : default\n",
        "     - 'github'\n",
        "    \"\"\"\n",
        "    self.df = pd.DataFrame() #this will contain final df to analyze\n",
        "    self.get()\n",
        "    self.state={}\n",
        "\n",
        "    ##Read the ini varible that contains all necessary paths\n",
        "    try:\n",
        "      with open('vars.ini', \"r\") as varsini:\n",
        "        vars_ini = json.load(varsini)\n",
        "        vars_ini['env'] = env\n",
        "    except Exception as e:\n",
        "      print('Please check vars.ini file')\n",
        "      raise(\"Can find 'vars.ini', ini varible that contains all necessary paths \")\n",
        "\n",
        "    self.vars={\n",
        "        'columns': {\n",
        "          'weight'   : {'def':'represents the information related to population counts','col':'weight'},\n",
        "          'nativity' : {'def':'Demographics-native country of mother', 'col': 'PEMNTVTY'}, #list of countries\n",
        "          'marital'  : {'def':'Demographics-marital status', 'col':'PEMARITL', 'val':{1:'Married', 2:'Not Married'}}, #1:'1,2', 2:'-1,3,4,5,6'},\n",
        "          'sex'      : {'def':'Demographics-sex', 'col':'PESEX', 'val':{1:'Male', 2:'Female'}}, #no change\n",
        "          'citiz'    : {'def':'Demographics-United States citizenship group', 'col':'PRCITSHP', 'val':{1:'Citizen', 2:'Not Citizen'}}, #1:'1,2,3,4', 2:'5'\n",
        "          'occ1'     : {'def': 'Primary Job', 'col':'PTIO1OCD'}, #list of occupations\n",
        "          'occ2'     : {'def':'Second Job', 'col':'PTIO2OCD'}, #list of occupations\n",
        "          'collegcred':{'def':'college credit completed', 'val':{1:'Four or more years college credit?', 2:'Less than 4 years'}}, #1:'5' 2: others\n",
        "          'highsch'     : {'def':'Second Job', 'col':'PEDIPGED', 'val':{1:'High School GED', 2:'No High School GED'}},  # 1:'1,2', 2:'-1'\n",
        "          'city'     : {'def':'Demographics-city level', 'col':'GTCBSA'},\n",
        "          'state'    : {'def':'Sate', 'col':'', 'val': json.loads(requests.get('https://api.census.gov/data/2024/cps/basic/jan/variables.json').text)['variables']['STATE']['values']['item']}\n",
        "        },\n",
        "        'new_census_data': False,\n",
        "        'varini': vars_ini\n",
        "    }\n",
        "\n",
        "    #Load Google Drive if current project reside on Colab\n",
        "    if self.vars['varini']['env'] == 'gdrive':\n",
        "      from google.colab import drive\n",
        "      drive.mount('/content/gdrive')\n",
        "\n",
        "  def get(self):\n",
        "    #TEST\n",
        "    #abc = requests.get('https://api.census.gov/data/2023/cps/basic/jan/variables.json')\n",
        "    #print(abc)\n",
        "    self.allVars_dict = {year_: year_vars for year_, year_vars in \\\n",
        "            zip(self.allYearList(), [json.loads(requests.get('https://api.census.gov/data/'+ str(year_) +'/cps/basic/jan/variables.json').text)['variables'] for year_ in self.allYearList()])}\n",
        "\n",
        "  @log_activity2\n",
        "  def allStatesIdList(self, year:int=2010):\n",
        "    return list(map(int, self.allVars_dict[year]['GESTFIPS']['values']['item'].keys())) #convert in int\n",
        "\n",
        "  @log_activity2\n",
        "  def allMonthList3TLA(self, specific_month=None):\n",
        "    month_dict = {1:\"jan\",2:\"feb\",3:\"mar\",4:\"apr\",5:\"may\",6:\"jun\",7:\"jul\",8:\"aug\",9: \"sep\",10: \"oct\",11:\"nov\",12:\"dec\"}\n",
        "    #return next(key for key, value in month_dict.items() if value == m)\n",
        "    if specific_month is None:\n",
        "      return list(month_dict.values())\n",
        "    else:\n",
        "      return [specific_month]\n",
        "\n",
        "  def allYearList(self):\n",
        "    return range(2010, 1+dt.now().year)\n",
        "\n",
        "  @log_activity2\n",
        "  def getVarsNameFromUrl(self, url):\n",
        "    return re.findall(r'([A-Z]+)', url)\n",
        "\n",
        "  def id_to_stateName(self,id):\n",
        "    return self.vars['columns']['state']['val'][str(id)]\n",
        "\n",
        "  def abbrev_to_id(self, abbrev):\n",
        "    for id, name in self.vars['columns']['state']['val'].items():\n",
        "        if name == abbrev:\n",
        "            return int(id)\n",
        "    return 0 #Not found\n",
        "\n",
        "  def abbrev_to_fullName(self, abbrev):\n",
        "      url = \"https://gist.githubusercontent.com/mshafrir/2646763/raw/8b0dbb93521f5d6889502305335104218454c2bf/states_hash.json\"\n",
        "      response = requests.get(url)\n",
        "      if response.status_code != 200:\n",
        "        print(\"Failed to fetch state names\")\n",
        "        return None\n",
        "      else:\n",
        "        state_names = response.json()\n",
        "        if abbrev.upper() in state_names:\n",
        "            return state_names[abbrev.upper()]\n",
        "        else:\n",
        "            return \"StateNotFound\"\n",
        "\n",
        "  def fullName_to_abbrev(self, fullName):\n",
        "      url = \"https://gist.githubusercontent.com/mshafrir/2646763/raw/8b0dbb93521f5d6889502305335104218454c2bf/states_hash.json\"\n",
        "      response = requests.get(url)\n",
        "      if response.status_code != 200:\n",
        "        print(\"Failed to fetch state names\")\n",
        "        return None\n",
        "      else:\n",
        "        state_names = response.json()\n",
        "        for abbrev, fname in state_names.items():\n",
        "            if fname == fullName:\n",
        "                return abbrev\n",
        "        return None #Not found\n",
        "\n",
        "#api=API('gdrive')"
      ],
      "metadata": {
        "id": "3AkeD9fuuu7V",
        "collapsed": true
      },
      "id": "3AkeD9fuuu7V",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(20) CLASS FileCompMix:"
      ],
      "metadata": {
        "id": "ecfQhoBJw4Me"
      },
      "id": "ecfQhoBJw4Me"
    },
    {
      "cell_type": "code",
      "source": [
        "class FileCompMix:\n",
        "  \"\"\"This class will track the which State Year and Month has already been processed\n",
        "  so we are ending up re-download the same file, knowing that we have close to 10,000 calls\n",
        "  to make with an average of 2.50 secs = ~ 7 hours in total.\n",
        "\n",
        "  Hou to?:\n",
        "  > track = FileCompMix(filename [optional])\n",
        "        - if filename contains any char then the class will generate a new fileName_%m%d-%H%M%.\n",
        "        - defaut is   ' MixCompStatus.csv '\n",
        "  > two main methods:\n",
        "        - track.record_state_of_state_year_month()   *   to store the info\n",
        "        - track.is_record_state_of_state_year_month  *   to check if elt exist already\n",
        "  \"\"\"\n",
        "  def isFolderExist(self, paths):\n",
        "    \"\"\"this method will check existance of folder, else will create them\n",
        "    \"\"\"\n",
        "    for path_key, path_value in paths.items():\n",
        "      print(path_key,'_', path_value)\n",
        "      if 'erged' in path_key:\n",
        "        print('erged - found')\n",
        "        if not os.path.exists(path_value):\n",
        "          os.makedirs(path_value)\n",
        "\n",
        "  def __init__(self, api) -> None:\n",
        "    fileName  = '' #dt.now().strftime(\"_%m%d-%H%M%S\")\n",
        "    path_root_folder = api.vars['varini'][api.vars['varini']['env']]\n",
        "    self.isFolderExist(path_root_folder)\n",
        "    self.gdrivePath = path_root_folder['unMergedPath']\n",
        "    self.track_file = self.gdrivePath + 'MixCompStatus' + fileName + '.csv'\n",
        "    self.set_df()\n",
        "    self.eltInFileList = [list(i) for i in self.df.values]\n",
        "\n",
        "\n",
        "  def set_df(self):\n",
        "    \"\"\"Read the NTFS file, and load it to a df so we can browse in in and download what has not been yet download\n",
        "    \"\"\"\n",
        "    try:\n",
        "      self.df = pd.read_csv(self.track_file, header=None)\n",
        "    except Exception as e:\n",
        "      self.df = pd.DataFrame([])\n",
        "    self.hasCSVdata = self.df.shape[0]\n",
        "\n",
        "  def numberOfelement(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def record_state_of_state_year_month(self, element):\n",
        "    self.df = pd.concat([self.df, pd.DataFrame([element])], ignore_index=True)\n",
        "    #print (f'__record_state_of_state_year_month__ len: {self.df.shape[0]}')\n",
        "    self.df.to_csv(self.track_file, mode='w', header=False, index=False) #not mode='a'\n",
        "    self.hasCSVdata = True\n",
        "\n",
        "  def is_record_state_of_state_year_month(self, element):\n",
        "    if not self.hasCSVdata:\n",
        "      #print ('--------------------------------#1F File emply, so will add')\n",
        "      return False\n",
        "    else:\n",
        "      if (list(element) in self.eltInFileList):\n",
        "        #print ('--------------------------------#2T elt already there, so not added, skipped')\n",
        "        return True\n",
        "      #print ('--------------------------------#3F, so will add')\n",
        "      return False"
      ],
      "metadata": {
        "id": "HfEeo6dFzYCL"
      },
      "id": "HfEeo6dFzYCL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(40) CLASS MIXCOMP"
      ],
      "metadata": {
        "id": "nZpi3PtBwkHG"
      },
      "id": "nZpi3PtBwkHG"
    },
    {
      "cell_type": "code",
      "source": [
        "# (40) CLASS MIXCOMP\n",
        "#Decorator to track API response time\n",
        "def track_response_time(func):\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(self, *args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        response_time = end_time - start_time\n",
        "        self.response_time = response_time  # Store in the class\n",
        "        print(f\"Function: '{func.__name__}()'. Census API query took: {response_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "#Class for unit-request (All State, specific Year, specific Month)\n",
        "class MixComp:\n",
        "  \"\"\"\n",
        "This class will pull the Mix composition about the US population from one state.\n",
        "Code\t    Label\n",
        "tabulate  Counts of instances\n",
        "PEMNTVTY\tDemographics-native country of mother\n",
        "PEMARITL\tDemographics-marital status\n",
        "PESEX\t    Demographics-sex\n",
        "PRCITSHP\tDemographics-United States citizenship group\n",
        "GTCBSA\t  Demographics-city level\n",
        "STATE\t    FIPS STATE Code\n",
        "GTCBSA\t  Demographics-city level\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, api, year, month):\n",
        "      #key = '&key='+'804d0a1a18d1de70764950c78e2a3a42d3d45e48' #w86\n",
        "      key = '&key='+'a24a131b4da25b83199bdc7202fcab553b9e2983' #luos\n",
        "      self.url = 'https://api.census.gov/data/'+str(year)+'/cps/basic/'+month+'?get=PWSSWGT,PEMNTVTY,PEMARITL,PESEX,PRCITSHP,PTIO1OCD,PTIO2OCD,PECYC,PEDIPGED,GTCBSA&for=state:*'+ key\n",
        "      self.gdrivePath = api.vars['varini'][api.vars['varini']['env']]['unMergedPath']\n",
        "      self.api = api\n",
        "      self.activityLog = 'activity.log'\n",
        "      self.year = year\n",
        "      self.month = month\n",
        "      self.response_time = 0 # how long the API took to run on Census CPS\n",
        "      self.dataAPI = None\n",
        "      self.dataText = None\n",
        "      self.data4Df = []\n",
        "      self.df = pd.DataFrame(None) #Will contain the final df(dataframe)\n",
        "      self.initLogger()\n",
        "\n",
        "  def initLogger(self):\n",
        "      # Create a logger\n",
        "      self.logger = logging.getLogger('activity_logger')\n",
        "      self.logger.setLevel(logging.INFO)\n",
        "      # Create a file handler and set the logging format\n",
        "      file_handler = logging.FileHandler(self.activityLog)\n",
        "      formatter = logging.Formatter('%(asctime)s - %(levelname)s - [w86] %(message)s')\n",
        "      file_handler.setFormatter(formatter)\n",
        "      # Add the file handler to the logger\n",
        "      self.logger.addHandler(file_handler)\n",
        "\n",
        "  def __str__(self):\n",
        "      return f\"\"\"\n",
        "      Mix Composition of the US population: month={self.month}, year={self.year}\n",
        "      Dataframe head:\n",
        "         {self.df.head(3)}\"\"\"\n",
        "\n",
        "  def __repr__(self):\n",
        "      return f\"MixComp({self.year}, {self.month})\"\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.df.shape[0]\n",
        "\n",
        "  def __add__(self, other):\n",
        "      return pd.concat([self.df, other.df], axis=0)\n",
        "\n",
        "  # to convert in class\n",
        "  def checkVariable(self, year, url):\n",
        "      \"\"\"This function will check if a set of variables are declared on the Census API. Using the an url as input. Vars are in ALL_CAPS\n",
        "      \"\"\"\n",
        "      matches = self.api.getVarsNameFromUrl(url)\n",
        "      cps_vars = self.api.allVars_dict[year].keys()\n",
        "      res = dict()\n",
        "      for var in matches:\n",
        "        res[var] = True if var in cps_vars else False\n",
        "      res['status'] = all([status for status in res.values()])\n",
        "      return res\n",
        "\n",
        "  @track_response_time\n",
        "  def get(self):\n",
        "      #This section will validate all variables and replace the city's with the right one if year>=2024 (GTCBSA->CBSA)\n",
        "      check = self.checkVariable(self.year, self.url)\n",
        "      print (f\"checkVariable() = {check}\")\n",
        "      if not check['status']:\n",
        "        self.logger.info(f\"> Class MixComp: / get() / BEFORE - Variables = {check}\")\n",
        "        if (self.year>=2024) and ('CBSA' not in check.keys()): #before 2024, City variable in 'GTCBSA', starting on 2024, City variable was 'CBSA'\n",
        "          self.url = re.sub('GTCBSA', 'CBSA', self.url)\n",
        "          self.logger.info(f\"Class MixComp: / get() / > AFTER -  Variables = {self.checkVariable(self.year, self.url)}\\nNew URL: {self.url}\")\n",
        "        else:\n",
        "          self.logger.info(f\"Class MixComp: / get() / > Please check all your Census variables. Unable to find some in the API call. Variables = {check}\")\n",
        "\n",
        "      try:\n",
        "        # download the Demographics_Native_Country_Of_Mother for Mix-Compostion\n",
        "        self.dataAPI = requests.get(self.url)\n",
        "        res = dict({'response time in secs': round(self.response_time,2), 'status': True if 200==self.dataAPI.status_code else False, 'code':self.dataAPI.status_code, 'comment': 'url:' + self.url})\n",
        "        self.logger.info(f'Class MixComp: / get() / > Return dict: [[[[ {res} ]]]]')\n",
        "        return res\n",
        "\n",
        "      except requests.exceptions.RequestException as e:\n",
        "          # Handle connection errors or HTTP errors\n",
        "          #raise(\"STOP ERROR: Tools for Data Science - Semester Project: An error occurred:\\n [[[[\", e, \"]]]]\")\n",
        "          self.logger.info(f'Class MixComp: / get() / > STOP ERROR: Tools for Data Science - Semester Project: An error occurred:\\n [[[[ {e} ]]]]')\n",
        "          self.logger.info(f'Class MixComp: / get() / > Skipped !!')\n",
        "      except AttributeError:\n",
        "          self.logger.info(f'Class MixComp: / get() / > STOP ERROR: Please check your variable name!')\n",
        "\n",
        "  def buildingDf(self):\n",
        "      \"\"\"\n",
        "      ##Definition of variables:\n",
        "      1. weight     represents the information related to population counts.\n",
        "      2. nativity   column provides information about the state\n",
        "      1. PEMNTVTY   Demographics-native country of mother\n",
        "      3. marital    Demographics-marital status\n",
        "      4. sex        Demographics-sex\n",
        "      5. citiz      Demographics-United States citizenship group\n",
        "      6. occ1       Primary Job\n",
        "      7. occ2       Second Job\n",
        "      8. collegcred college credit completed\n",
        "      5. city       Demographics-city level\n",
        "      We will understand the population composition by state about how mixed it is based on the native country of mothers,\n",
        "      marital status distribution, gender demographics, citizenship status, at the city-level characteristics.\n",
        "      This data can be used to uncover trends, patterns, and insights into the social and cultural fabric of the US population.\n",
        "      \"\"\"\n",
        "      ##Build df and Renmane Df Columns for easy reading.\n",
        "      self.df = pd.DataFrame(list(json.loads(self.dataAPI.text))[1:],columns = ['weight', 'nativity', 'marital', 'sex', 'citiz', 'occ1','occ2', 'collegcred','highsch', 'city', 'state'])\n",
        "      ##Remove unknown City ID city==0\n",
        "      self.df = self.df[self.df['city']!='0']\n",
        "      self.logger.info(f'Class MixComp: / buildingDf > Remove unknown City ID, Build df and Renmane Df Columns for easy reading.')\n",
        "      ##Building the YYYYMM column\n",
        "      self.df['YYYYMM'] = dt.strptime(str(self.year)+ '-' +str(self.month), \"%Y-%b\")\n",
        "      self.logger.info(f'Class MixComp: / buildingDf > Built Dataframe for YYYYMM:{str(self.year)}-{str(self.month)}')\n",
        "      #convert column in true type 'citiz', 'occ1','occ2', 'collegcred','highsch', 'city', 'state'])\n",
        "      self.df['weight'] = self.df['weight'].astype(float)\n",
        "      self.df['nativity'] = self.df['nativity'].astype(int)\n",
        "      self.df['marital'] = self.df['marital'].astype(int)\n",
        "      self.df['sex'] = self.df['sex'].astype(int)\n",
        "      self.df['citiz'] = self.df['citiz'].astype(int)\n",
        "      self.df['occ1'] = self.df['occ1'].astype(int)\n",
        "      self.df['occ2'] = self.df['occ2'].astype(int)\n",
        "      self.df['collegcred'] = self.df['collegcred'].astype(int)\n",
        "      self.df['highsch'] = self.df['highsch'].astype(int)\n",
        "      self.df['city'] = self.df['city'].astype(int)\n",
        "      self.df['state'] = self.df['state'].astype(int)\n",
        "      #convert content with relevant information\n",
        "      self.df['marital'] = self.df['marital'].apply(lambda x: 1 if x in [1,2] else 2)\n",
        "      self.df['citiz'] = self.df['citiz'].apply(lambda x: 1 if x in [1,2,3,4] else 2)\n",
        "      self.df['collegcred'] = self.df['collegcred'].apply(lambda x: 1 if x in [5] else 2)\n",
        "      self.df['highsch'] = self.df['highsch'].apply(lambda x: 1 if x in [1,2] else 2)\n",
        "\n",
        "  def save(self, file=''):\n",
        "      try:\n",
        "        if file == '':\n",
        "          file = str(self.year)+'-'+ str(self.month)+'-MixComp.csv'\n",
        "        r = self.df.to_csv( self.gdrivePath + file, index=False)\n",
        "        self.logger.info(f'Class MixComp: / save > Created CSV file: {file}')\n",
        "        return r\n",
        "      except FileNotFoundError:\n",
        "        raise (f'Check the path {file} of the file')\n",
        "        self.logger.info(f'Class MixComp: / save > Check the path {file} of the file')\n",
        "        self.logger.info(f'Class MixComp: / save > Skipped {file} creation')\n",
        "\n",
        "  def main(self):\n",
        "      self.logger.info(f\"> {'v'*30} year:{self.year},month:{self.month} {'v'*30}\")\n",
        "      self.logger.info(f'Class MixComp: / main >  method - Entrance')\n",
        "      self.logger.info(f'>Class MixComp: / main > get() method')\n",
        "\n",
        "      url_call = self.get()\n",
        "      self.logger.info(f'Class MixComp: / main - line: get() method - Result:{url_call}')\n",
        "\n",
        "      try:\n",
        "        if url_call['status']:\n",
        "          self.buildingDf();  self.logger.info(f'Class MixComp: / main > URL found (200), now Creating the df')\n",
        "          self.save();        self.logger.info(f'Class MixComp: / main > save() method')\n",
        "        else:\n",
        "          self.logger.info(f\"Class MixComp: / main > Error during URL call, Code return: {url_call['code']}, Skipped !!\")\n",
        "      except Exception as e:\n",
        "        self.logger.info(f\"Class MixComp: / main > Error during URL call, Code return was undefinied, !! Please also check the API KEY!! Skipped !!\")\n",
        "      self.logger.info(f'Class MixComp: / main > Called main(self) method - End')\n",
        "      self.logger.info(f\"> {'^'*90}\")\n",
        "      return url_call\n"
      ],
      "metadata": {
        "id": "pkTeNx4nLZy8"
      },
      "id": "pkTeNx4nLZy8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(60#1) CORE #01 (this section will create individual files: yyyy-mm-MixComp.csv)"
      ],
      "metadata": {
        "id": "FaDs85AMwyIy"
      },
      "id": "FaDs85AMwyIy"
    },
    {
      "cell_type": "code",
      "source": [
        "## (60 - 1) Going through All Months at once\n",
        "\n",
        "def single_file_generator_01(api):\n",
        "  track = FileCompMix(api)\n",
        "  count = {'initiallyInFile': track.numberOfelement(), 'processed': 0, 'skipped': 0}\n",
        "  print ('Begin>',count)\n",
        "\n",
        "  for year in api.allYearList():\n",
        "    for month in api.allMonthList3TLA('jun'): #remove 'jun' for all months:\n",
        "      elt = [year,month]\n",
        "      if not track.is_record_state_of_state_year_month(elt):\n",
        "        dataA = MixComp(api, *elt) #(year, month)\n",
        "\n",
        "        result = dataA.main()\n",
        "        count['processed'] += 1\n",
        "        if result['status']:\n",
        "          track.record_state_of_state_year_month(elt)\n",
        "          api.vars['new_census_data'] = True\n",
        "      else:\n",
        "        count['skipped'] += 1\n",
        "\n",
        "  print ('\\nEnd  <',count)\n",
        "  print (f\"new_census_data: {api.vars['new_census_data']}, count['processed']: {count['processed']},count['skipped']: {count['skipped']}\")"
      ],
      "metadata": {
        "id": "l6wJsLXwmypE",
        "collapsed": true
      },
      "id": "l6wJsLXwmypE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(60#2) CORE #02 Merging to one (this section will create individual files: yyyy-Merged.csv)"
      ],
      "metadata": {
        "id": "7HyvZXuubh66"
      },
      "id": "7HyvZXuubh66"
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_02(api, force=False):\n",
        "    \"\"\"Merge all single file in one and\n",
        "    Will transfer all done file in a folder \"mergedByYear\"\n",
        "    if force=True, the script will run whether we have new census data available\n",
        "    or not -> api.vars['new_census_data']\n",
        "    \"\"\"\n",
        "    if not (api.vars['new_census_data'] or force): return None\n",
        "    filenameList = os.listdir(api.vars['varini'][api.vars['varini']['env']]['unMergedPath'])\n",
        "    filenameList = [file for file in filenameList if re.match(r'^\\d{4}', file)]\n",
        "\n",
        "    print (filenameList)\n",
        "    \"Example: 2010-apr-MixComp.csv\"\n",
        "\n",
        "    for file in filenameList:\n",
        "      year = file.split('-')[0]\n",
        "      if (int(year)>=2010) and (int(year)<=2024):\n",
        "        if year not in api.vars['varini'][api.vars['varini']['env']]['yearly']:\n",
        "          api.vars['varini'][api.vars['varini']['env']]['yearly'][year]=[]\n",
        "        df = pd.read_csv(api.vars['varini'][api.vars['varini']['env']]['unMergedPath'] + file)\n",
        "        api.vars['varini'][api.vars['varini']['env']]['yearly'][year].append(df)\n",
        "\n",
        "    api.vars['varini'][api.vars['varini']['env']]['fused'] = {}\n",
        "    for year, dfs in api.vars['varini'][api.vars['varini']['env']]['yearly'].items():\n",
        "      api.vars['varini'][api.vars['varini']['env']]['fused'][year] = pd.concat(dfs)\n",
        "\n",
        "    for year, df in api.vars['varini'][api.vars['varini']['env']]['fused'].items():\n",
        "      path = api.vars['varini'][api.vars['varini']['env']]['merged']\n",
        "      df.to_csv(f'{path}{year}_merged.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Oh8btjJvbhdL"
      },
      "id": "Oh8btjJvbhdL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(60#3) CORE #03 Group By using merged files (will generated new files in folder Merged2 | files: yyyy-Merged.csv)"
      ],
      "metadata": {
        "id": "a3jMq3YeUSrP"
      },
      "id": "a3jMq3YeUSrP"
    },
    {
      "cell_type": "code",
      "source": [
        "def group_by_03(api, force=False):\n",
        "  \"\"\"Read the merged file by year and group column in a different folder 'mergedByYear2'\n",
        "  \"\"\"\n",
        "  if not (api.vars['new_census_data'] or force): return None\n",
        "  filenameList = os.listdir(api.vars['varini'][api.vars['varini']['env']]['merged'])\n",
        "  filenameList = [file for file in filenameList if re.match(r'^\\d{4}', file)]\n",
        "  \"\"\"filenameList = iter(filenameList)\n",
        "  file = next(filenameList)\n",
        "  print (f'file:{file}')\n",
        "  \"\"\"\n",
        "  for file in filenameList:\n",
        "    print (f'file:{file}')\n",
        "    df = pd.read_csv (api.vars['varini'][api.vars['varini']['env']]['merged'] + file)\n",
        "    print (df.columns)\n",
        "\n",
        "    grouped = df.groupby(['state', 'nativity', 'marital', 'sex', 'citiz', 'occ1', 'occ2',\n",
        "                        'collegcred', 'highsch', 'city', 'YYYYMM'])['weight'].sum().reset_index()\n",
        "    grouped.to_csv(f\"{api.vars['varini'][api.vars['varini']['env']]['merged2']}{file}\")\n"
      ],
      "metadata": {
        "id": "mtl75cJt5qmh",
        "collapsed": true
      },
      "id": "mtl75cJt5qmh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(70) #04 Single df for all years"
      ],
      "metadata": {
        "id": "l0wKMRiWU6hJ"
      },
      "id": "l0wKMRiWU6hJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def readCSV_and_fuse_dfs_04(api):\n",
        "  \"\"\"read all files in a single df\n",
        "  return a new api.df\n",
        "  \"\"\"\n",
        "  filenameList = os.listdir(api.vars['varini'][api.vars['varini']['env']]['merged2'])\n",
        "  filenameList = [file for file in filenameList if re.match(r'^\\d{4}', file)]\n",
        "  list_df=[]\n",
        "  for file in filenameList:\n",
        "    df = pd.read_csv (api.vars['varini'][api.vars['varini']['env']]['merged2'] + file)\n",
        "    list_df.append(df)\n",
        "  df = pd.concat(list_df)\n",
        "  return df\n",
        "  #print (f'__ All shape: {df.shape}')\n",
        "  #df.to_csv(api.vars['varini'][api.vars['varini']['env']]['merged2'] + 'group.csv')\n"
      ],
      "metadata": {
        "id": "PFU9Ualv5gvt"
      },
      "id": "PFU9Ualv5gvt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Version:\n",
        "05/11 08:28\n",
        "ready to import packages\n",
        "\n",
        "from censustools import *"
      ],
      "metadata": {
        "id": "NoPjWN5o1KAF"
      },
      "id": "NoPjWN5o1KAF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MAIN function"
      ],
      "metadata": {
        "id": "qXe5upGtvBJt"
      },
      "id": "qXe5upGtvBJt"
    },
    {
      "cell_type": "code",
      "source": [
        "api2=API('gdrive')"
      ],
      "metadata": {
        "id": "9cKwidQwSSg1",
        "outputId": "e67545e1-396f-48b8-be0c-ada6f8e40b19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9cKwidQwSSg1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api2.vars['columns']['citiz']"
      ],
      "metadata": {
        "id": "llJEMQoOSU9V",
        "outputId": "88351208-73bc-4f34-94c7-db893531e64c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "llJEMQoOSU9V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'def': 'Demographics-United States citizenship group',\n",
              " 'col': 'PRCITSHP',\n",
              " 'val': {1: 'Citizen', 2: 'Not Citizen'}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api2=API('github')\n",
        "single_file_generator_01(api2)\n",
        "merge_02(api2)\n",
        "group_by_03(api2)\n",
        "api2.df = readCSV_and_fuse_dfs_04(api2)\n",
        "api2.df.head()"
      ],
      "metadata": {
        "id": "2CSJ6HgNugZd"
      },
      "id": "2CSJ6HgNugZd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- ALONE ------ ## (01)\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import json\n",
        "import logging\n",
        "from censustools import *\n",
        "\n",
        "api2=API('gdrive')\n",
        "#api2.df = readCSV_and_fuse_dfs_04(api2)\n",
        "#api2.df.head()"
      ],
      "metadata": {
        "id": "-mGJfLL8XSBV",
        "outputId": "50c26464-da2c-48fc-ca68-20e8c89ba972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-mGJfLL8XSBV",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##(02)\n",
        "api2.df = readCSV_and_fuse_dfs_04(api2)\n",
        "df=api2.df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MB8dV_5SdOZS"
      },
      "id": "MB8dV_5SdOZS",
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: Graphics (Streamlit, ...)"
      ],
      "metadata": {
        "id": "1nxK_syeA96T"
      },
      "id": "1nxK_syeA96T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Graph display CODE 1"
      ],
      "metadata": {
        "id": "l_wWttWGOLFP"
      },
      "id": "l_wWttWGOLFP"
    },
    {
      "cell_type": "code",
      "source": [
        "## (03)\n",
        "\"\"\"\n",
        "choose_year     = pd.to_datetime(df['YYYYMM']).dt.year==2010\n",
        "choose_state    = df['state']==10\n",
        "choose_month    = pd.to_datetime(df['YYYYMM']).dt.month==5\n",
        "choose_marital  = None\n",
        "choose_citiz    = None\n",
        "choose_collegcred = None\n",
        "choose_highsch  = None\n",
        "\"\"\"\n",
        "choose_year     = None\n",
        "choose_year     = pd.to_datetime(df['YYYYMM']).dt.year==2010\n",
        "choose_state    = None\n",
        "#choose_state    = df['state']==20\n",
        "choose_marital  = None\n",
        "#choose_marital  = df['marital']== 1\n",
        "choose_citiz    = None\n",
        "#choose_citiz    = df['citiz']== 1\n",
        "choose_collegcred = None\n",
        "#choose_collegcred = df['collegcred']== 1\n",
        "choose_highsch  = None\n",
        "#choose_highsch  = df['highsch']== 2\n",
        "\n",
        "condition = None\n",
        "\n",
        "if choose_year is not None:\n",
        "  if condition is None: condition = choose_year\n",
        "  else: condition &= choose_year\n",
        "\n",
        "if choose_state is not None:\n",
        "  if condition is None: condition = choose_state\n",
        "  else: condition &= choose_state\n",
        "\n",
        "if choose_marital is not None:\n",
        "  if condition is None: condition = choose_marital\n",
        "  else: condition &= choose_marital\n",
        "\n",
        "if choose_citiz is not None:\n",
        "  if condition is None: condition = choose_citiz\n",
        "  else: condition &= choose_citiz\n",
        "\n",
        "if choose_collegcred is not None:\n",
        "  if condition is None: condition = choose_collegcred\n",
        "  else: condition &= choose_collegcred\n",
        "\n",
        "if choose_highsch is not None:\n",
        "  if condition is None: condition = choose_highsch\n",
        "  else: condition &= choose_highsch\n",
        "\n",
        "#if none selected display everything\n",
        "if condition is None: condition=pd.Series([True] * len(df))\n",
        "\n",
        "#g2 = df [(pd.to_datetime(df['YYYYMM']).dt.month==5) & (df['state']==10)]\n",
        "g2 = df [condition]\n",
        "\n",
        "\n",
        "#[STATE LEVEL] -------  Display the 7 highest population\n",
        "\n",
        "g2 = g2.groupby(['state'])['weight'].sum().reset_index().sort_values(by='weight', ascending=False).head(7)\n",
        "g2['state'] = g2['state'].apply(lambda x: api2.id_to_stateName(x))\n"
      ],
      "metadata": {
        "id": "xNnjsKD4PoD0"
      },
      "id": "xNnjsKD4PoD0",
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [CITY LEVEL]\n",
        "def city_state(long_city:str)-> str:\n",
        "  try:\n",
        "    parts = long_city.split(',')\n",
        "    city_name = parts[0].split('-')[0].strip()\n",
        "    state_abbr = parts[1].split('-')[0].strip()\n",
        "  except Exception as e:\n",
        "    #print (f\"City is not having the sanme format (cities, ST): {long_city}\")\n",
        "    #like Bloomington-Normal IL with no SPACE (important)\n",
        "    pattern = r'([\\s\\S]*)([A-Z]{2})'\n",
        "    res = re.search(pattern, long_city)\n",
        "    city_name = res.group(1).strip()\n",
        "    state_abbr = res.group(2).strip()\n",
        "  return f\"{city_name} {state_abbr}\"\n",
        "\n",
        "def cityID_to_fullNames(CBSA_Id):\n",
        "  return api2.allVars_dict[2010]['GTCBSA']['values']['item'][str(CBSA_Id)]\n",
        "\n",
        "city_data = g2.groupby(['city'])['weight'].sum().reset_index().sort_values(by='weight', ascending=False)\n",
        "city_data['cityFullName'] = city_data['city'].apply(lambda cityID: cityID_to_fullNames(cityID))\n",
        "city_data['cityName'] = city_data['cityFullName'].apply(lambda cityID: city_state (cityID))\n",
        "#city_data.head(2)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "OY21Vu9IxZAj",
        "outputId": "c64b7289-7ea5-4f52-9f8c-89d6dbb48b10"
      },
      "id": "OY21Vu9IxZAj",
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'city'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-20111834dfe1>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mapi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallVars_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2010\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GTCBSA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCBSA_Id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcity_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mcity_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cityFullName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcityID\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcityID_to_fullNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcityID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcity_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cityName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cityFullName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcityID\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcity_state\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcityID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8250\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8252\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   8253\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8254\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'city'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Graph display PLOT"
      ],
      "metadata": {
        "id": "KzF-tL77lpFM"
      },
      "id": "KzF-tL77lpFM"
    },
    {
      "cell_type": "code",
      "source": [
        "df = city_data.copy()\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Load GeoJSON file for US cities\n",
        "with open('us_cities.geojson', 'r') as f:\n",
        "    geojson_data = json.load(f)\n",
        "\n",
        "coordinates_list =[]\n",
        "df_all_cities = pd.unique(df['cityName'])\n",
        "for feature in geojson_data['features']:\n",
        "    city_name = feature['properties']['name']\n",
        "    if city_name in df_all_cities:\n",
        "      ind   = df.index[df['cityName'] == city_name].tolist()[0]\n",
        "      coord = feature['geometry']['coordinates']\n",
        "      #print (f\"{ind}:{coord}\")\n",
        "      coordinates_list.append ([ind, coord])\n",
        "\n",
        "coordinates_dict = {ind: coord for ind, coord in coordinates_list}\n",
        "df = df[df.index.isin(coordinates_dict.keys())] #delete all cities with error in their name\n",
        "df['coordinate'] = df.index.map(lambda x: coordinates_dict[x])\n",
        "\n",
        "#Display the US map\n",
        "fig = px.scatter_geo(df,\n",
        "                     lon=[coord[0] for coord in df['coordinate']],\n",
        "                     lat=[coord[1] for coord in df['coordinate']],\n",
        "                     hover_name='cityFullName',\n",
        "                     size='weight',\n",
        "                     color='weight',\n",
        "                     scope='usa',\n",
        "                     color_continuous_scale='Viridis')\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tu4UtZC4uVd8",
        "outputId": "0b8270d7-63e9-4a46-b371-686da984c228"
      },
      "id": "tu4UtZC4uVd8",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"db0af0dd-52a0-4c6d-8d6b-76491882228c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"db0af0dd-52a0-4c6d-8d6b-76491882228c\")) {                    Plotly.newPlot(                        \"db0af0dd-52a0-4c6d-8d6b-76491882228c\",                        [{\"geo\":\"geo\",\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eweight=%{marker.color}\\u003cbr\\u003elat=%{lat}\\u003cbr\\u003elon=%{lon}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"New York-Northern New Jersey-Long Island, NY-NJ-PA (Pennsylvania portion not in sample\",\"Los Angeles-Long Beach-Santa Ana, CA\",\"Houston-Baytown-Sugar Land, TX\",\"Miami-Fort Lauderdale-Miami Beach, FL\",\"Philadelphia-Camden-Wilmington, PA-NJ-DE\",\"Boston-Cambridge-Quincy, MA-NH\",\"Detroit-Warren-Livonia, MI\",\"San Francisco-Oakland-Fremont, CA\",\"Phoenix-Mesa-Scottsdale, AZ\",\"Riverside-San Bernardino, CA\",\"Seattle-Tacoma-Bellevue, WA\",\"Minneapolis-St Paul-Bloomington, MN-WI (Wisconsin portion not identified)\",\"San Diego-Carlsbad-San Marcos, CA\",\"Baltimore-Towson, MD\",\"Tampa-St. Petersburg-Clearwater, FL\",\"Denver-Aurora, CO\",\"Portland-Vancouver-Beaverton, OR-WA (Yamhill County, OR not in sample)\",\"Cleveland-Elyria-Mentor, OH\",\"San Jose-Sunnyvale-Santa Clara, CA\",\"Pittsburgh, PA\",\"San Antonio, TX\",\"Orlando, FL\",\"Sacramento--Arden-Arcade Roseville, CA\",\"Kansas City, MO-KS (Franklin, KS; Leavenworth, KS; Linn, KS; Bates, MO; and Caldwell,\",\"Cincinnati-Middletown, OH-KY-IN (Franklin County , IN not in sample; Dearborn and Ohio\",\"Charlotte-Gastonia-Concord, NC-SC (Anson County, NC not in sample)\",\"Las Vegas-Paradise, NV\",\"Indianapolis, IN\",\"Austin-Round Rock, TX\",\"Milwaukee-Waukesha-West Allis, WI\",\"Virginia Beach-Norfolk-Newport News, VA-NC (North Carolina portion not identified)\",\"Jacksonville, FL\",\"Oklahoma City, OK\",\"Memphis, TN-MS-AR (Arkansas portion not identified and Tunica County, MS not in sample\",\"Louisville, KY-IN (Washington, IN; Henry, KY; Nelson, KY; Shelby, KY; and Trimble, KY\",\"New Orleans-Metairie-Kenner, LA\",\"Birmingham-Hoover, AL\",\"Hartford-West Hartford-East Hartford, CT\",\"Tucson, AZ\",\"Buffalo-Niagara Falls, NY\",\"Allentown-Bethlehem-Easton, PA-NJ\",\"Albuquerque, NM\",\"Rochester, NY\",\"Raleigh-Cary, NC\",\"Fresno, CA\",\"Bridgeport-Stamford-Norwalk, CT\",\"Grand Rapids-Wyoming, MI\",\"Oxnard-Thousand Oaks-Ventura, CA\",\"Albany-Schenectady-Troy, NY\",\"Honolulu, HI\",\"Greensboro-High Point, NC\",\"El Paso, TX\",\"Baton Rouge, LA\",\"Omaha-Council Bluffs, NE-IA\",\"Dayton, OH\",\"Springfield, MA-CT (Connecticut portion not identified)\",\"Charleston-North Charleston, SC\",\"Deltona-Daytona Beach-Ormond Beach, FL\",\"Columbia, SC\",\"Bakersfield, CA\",\"Syracuse, NY\",\"Wichita, KS\",\"Lafayette, LA\",\"Akron, OH\",\"Harrisburg-Carlisle, PA\",\"Stockton, CA\",\"Colorado Springs, CO\",\"New Haven, CT\",\"Palm Bay-Melbourne-Titusville, FL\",\"Jackson, MS\",\"Durham, NC\",\"Madison, WI\",\"Santa Rosa-Petaluma, CA\",\"Ogden-Clearfield, UT\",\"Chattanooga, TN-GA\",\"Monroe, LA\",\"Modesto, CA\",\"Cape Coral-Fort Myers, FL\",\"Des Moines, IA\",\"Scranton-Wilkes Barre, PA\",\"Savannah, GA\",\"Reading, PA\",\"Victoria, TX\",\"Vallejo-Fairfield, CA\",\"Lexington-Fayette, KY\",\"Corpus Christi, TX\",\"Reno-Sparks, NV\",\"Huntsville, AL\",\"Pensacola-Ferry Pass-Brent, FL\",\"Spokane, WA\",\"Santa Barbara-Santa Maria-Goleta, CA\",\"Lancaster, PA\",\"Mobile, AL\",\"Youngstown-Warren-Boardman, OH\",\"Lakeland-Winter Haven, FL\",\"Fayetteville- Springdale-Rogers, AR-MO (Madison County, AR and Missouri portion not in\",\"Worcester, MA-CT (Connecticut portion not identified)\",\"Boulder, CO\",\"Canton-Massillon, OH\",\"Salem, OR\",\"Salinas, CA\",\"Lansing-East Lansing, MI\",\"Portland-South Portland, ME\",\"Brownsville-Harlingen, TX\",\"Peoria, IL\",\"Atlantic City, NJ\",\"Madera, CA\",\"Montgomery, AL\",\"Rockford, IL\",\"Davenport-Moline-Rock Island, IA-IL\",\"Flint, MI\",\"Columbus, GA-AL (Harris County, GA not in sample)\",\"South Bend-Mishawaka, IN-MI (Michigan portion not identified)\",\"Fort Wayne, IN\",\"Waco, TX\",\"Laredo, TX\",\"Visalia-Porterville, CA\",\"Fayetteville, NC\",\"Eugene-Springfield, OR\",\"Kalamazoo-Portage, MI\",\"Yakima, WA\",\"Barnstable Town, MA\",\"Trenton-Ewing, NJ\",\"Eau Claire, WI\",\"Greeley, CO\",\"Killeen-Temple-Fort Hood, TX\",\"Decatur, IL\",\"Tallahassee, FL\",\"Utica-Rome, NY\",\"Fort Collins-Loveland, CO\",\"Beaumont-Port Author, TX\",\"Jacksonville, NC\",\"Decatur, AL\",\"Muskegon-Norton Shores, MI\",\"Erie, PA\",\"Olympia, WA\",\"Kingsport-Bristol, TN-VA (Virginia portion not identified)\",\"Fort Smith, AR-OK (Oklahoma portion not in sample)\",\"Sioux Falls, SD\",\"Ann Arbor, MI\",\"Saginaw-Saginaw Township North, MI\",\"Evansville, IN-KY (Gibson County, IN and Kentucky portion not in sample)\",\"Merced, CA\",\"Prescott, AZ\",\"Binghamton, NY\",\"Chico, CA\",\"Springfield, IL\",\"Ocala, FL\",\"San Luis Obispo-Paso Robles, CA\",\"Midland, TX\",\"Pueblo, CO\",\"Harrisonburg, VA\",\"Napa, CA\",\"Bend, OR\",\"Joplin, MO\",\"Racine, WI\",\"Bremerton-Silverdale, WA\",\"Bellingham, WA\",\"Altoona, PA\",\"Appleton,WI\",\"Anderson, IN\",\"Lawton, OK\",\"Medford, OR\",\"Janesville, WI\",\"Duluth, MN-WI (Carlton County, MN not in sample, WI portion not identified)\",\"Leominster-Fitchburg-Gardner, MA\",\"Lawrence, KS\",\"Johnson City, TN\",\"Oshkosh-Neenah, WI\",\"Huntington-Ashland, WV-KY-OH (Kentucky and Ohio portions not in sample)\",\"Waterbury, CT\",\"Fargo, ND-MN (MN portion not identified)\",\"Warner Robins, GA\",\"Dover, DE\",\"Gulfport-Biloxi, MS\",\"Coeur d'Alene, ID\",\"Farmington, NM\",\"Danbury, CT\",\"Vineland-Millville-Bridgeton, NJ\",\"Springfield, OH\",\"Santa Fe, NM\",\"Bowling Green, KY\"],\"lat\":[40.67,34.11,29.77,25.78,40.01,42.34,42.38,37.77,33.54,33.94,47.62,44.96,32.81,39.3,27.96,39.77,45.54,41.48,37.3,40.44,29.46,28.5,38.57,39.12,39.14,35.2,36.21,39.78,30.31,43.06,36.74,30.33,35.47,35.11,38.22,30.07,33.53,41.77,32.2,42.89,40.6,35.12,43.17,35.82,36.78,41.19,42.96,34.2,42.67,21.32,36.08,31.85,30.45,41.26,39.78,42.12,32.79,28.91,34.04,35.36,43.04,37.69,30.22,41.08,40.28,37.97,38.86,41.31,27.99,32.32,35.98,43.08,38.45,41.23,35.07,32.51,37.66,26.64,41.58,41.4,32.02,40.34,28.82,38.11,38.04,27.71,39.54,34.71,30.44,47.67,34.43,40.04,30.68,41.1,28.04,36.07,42.27,40.03,40.81,44.92,36.68,42.71,43.66,25.93,40.74,39.38,36.97,32.35,42.27,41.56,43.02,32.51,41.68,41.07,31.57,27.53,36.33,35.07,44.05,42.27,46.59,41.7,40.22,44.82,40.42,31.1,39.85,30.46,43.1,40.56,30.09,34.76,34.57,43.23,42.13,47.04,36.53,35.37,43.54,42.28,43.42,37.98,37.3,34.58,42.1,39.75,39.78,29.19,35.27,32.03,38.27,38.44,38.3,44.07,37.08,42.73,47.55,48.74,40.51,44.27,40.09,34.6,42.34,42.68,46.78,42.52,38.96,36.33,44.02,38.41,41.56,46.88,32.61,39.16,30.39,47.7,36.75,41.4,39.46,39.93,35.68,36.97],\"legendgroup\":\"\",\"lon\":[-73.94,-118.41,-95.39,-80.21,-75.13,-71.02,-83.1,-122.45,-112.07,-117.4,-122.35,-93.27,-117.14,-76.61,-82.48,-104.87,-122.66,-81.68,-121.85,-79.98,-98.51,-81.37,-121.47,-94.55,-84.51,-80.83,-115.22,-86.15,-97.75,-87.97,-76.04,-81.66,-97.51,-90.01,-85.74,-89.93,-86.8,-72.68,-110.89,-78.86,-75.48,-106.62,-77.62,-78.66,-119.79,-73.2,-85.66,-119.21,-73.8,-157.8,-79.83,-106.44,-91.13,-96.01,-84.2,-72.54,-79.99,-81.21,-80.89,-119.0,-76.14,-97.34,-92.03,-81.52,-76.88,-121.31,-104.76,-72.92,-80.66,-90.21,-78.91,-89.39,-122.7,-111.97,-85.26,-92.08,-120.99,-82.0,-93.62,-75.67,-81.13,-75.93,-96.98,-122.26,-84.46,-97.29,-119.82,-86.63,-87.19,-117.41,-119.72,-76.3,-88.09,-80.65,-81.96,-94.16,-71.81,-105.25,-81.37,-123.02,-121.64,-84.55,-70.28,-97.48,-89.61,-74.45,-120.08,-86.28,-89.06,-90.6,-83.69,-84.87,-86.27,-85.14,-97.18,-99.49,-119.32,-78.9,-123.11,-85.59,-120.53,-70.3,-74.76,-91.49,-104.74,-97.72,-88.93,-84.28,-75.23,-105.07,-94.14,-77.4,-86.99,-86.26,-80.09,-122.89,-82.56,-94.38,-96.73,-83.73,-83.95,-87.54,-120.48,-112.45,-75.91,-121.81,-89.64,-82.13,-120.66,-102.1,-104.62,-78.87,-122.3,-121.31,-94.5,-87.81,-122.7,-122.47,-78.4,-88.4,-85.69,-98.42,-122.85,-89.02,-92.12,-71.77,-95.26,-82.37,-88.55,-82.43,-73.04,-96.82,-83.63,-75.53,-89.07,-116.78,-108.19,-73.47,-75.0,-83.8,-105.95,-86.44],\"marker\":{\"color\":[19016476.7673,12908995.6845,5846010.283,5687266.1593,5533722.0199,4639509.5485,4525840.2231,4402023.5329,4311484.488,3841033.0779999997,3499282.719,3176076.0395,2777427.4106,2748573.1103,2694502.5407000002,2551649.235,2266081.5898,2234923.6869,2198152.1279,2162241.5253,2123580.4141,2077486.2183,2001900.357,1931303.7406,1917163.3136,1891079.4475,1821227.8442,1785986.2077,1636645.7071,1547971.0348,1531526.6345,1396502.0347,1325517.7693,1247904.9351,1223074.5695,1191765.4584,1183283.5095,1181422.0349,1130917.9376,1130656.9944,1116415.5479000001,1077754.0825,1055647.8222999999,1048075.4393,933134.8605,930577.8893,927315.127,925694.0499,918267.6427,912771.1579,881239.6855,857644.6690999999,845330.4951000001,822755.6666,805207.4352,731638.696,712181.8837,694633.2557,685696.7758,683199.7032,646059.2383,645403.5736,640519.3984,635598.8298,628635.9906,622561.7652,614226.6775,600360.6001,589807.1469,579107.3077,577672.4211,576781.4972,574247.8318,571721.5168,556780.0535,556488.0809,553125.1955,543015.2119999999,538918.1867,525602.0118,515334.1329,505577.5193,498366.3073,486195.0386,482071.5599,479375.2956,472577.512,463199.9469,457240.2789,455656.82389999996,447808.8906,446719.3681,443138.5563,437118.7481,436680.39009999996,428321.674,425779.9142,423647.2566,420067.2969,416903.8039,405197.3294,402013.5048,391302.8889,385524.8919,384647.8623,383559.0443,382739.0974,379976.3676,378228.3584,377009.4748,376856.0211,365714.3232,365147.865,360576.8282,357349.9085,357112.6357,350913.1592,345289.6665,345083.5578,336495.3318,335127.3678,328057.5404,326016.0657,318138.1483,317857.7695,310303.4508,298992.1114,298624.4441,296971.9589,289939.0104,289121.942,287435.0604,278801.4056,266286.7496,262650.6953,256850.1229,252167.6116,250487.6803,250124.8843,247960.5772,245053.9986,244413.906,241807.1721,239309.195,239159.5333,239027.9754,235934.9434,231901.66460000002,228782.30730000001,225543.97830000002,224931.6565,221305.0102,218303.8046,217157.4441,214923.9535,213538.3396,209424.62159999998,206248.0009,204492.7316,203691.4106,202471.6264,199079.6582,196175.3934,192623.0161,181371.1613,177808.0796,164944.9022,161057.3006,160451.3347,155870.7573,149383.5031,146332.2604,143982.4333,142817.0669,135582.234,124029.813,108214.6836,97544.6321,92674.5128,89850.6637,80665.1974,60370.6896],\"coloraxis\":\"coloraxis\",\"size\":[19016476.7673,12908995.6845,5846010.283,5687266.1593,5533722.0199,4639509.5485,4525840.2231,4402023.5329,4311484.488,3841033.0779999997,3499282.719,3176076.0395,2777427.4106,2748573.1103,2694502.5407000002,2551649.235,2266081.5898,2234923.6869,2198152.1279,2162241.5253,2123580.4141,2077486.2183,2001900.357,1931303.7406,1917163.3136,1891079.4475,1821227.8442,1785986.2077,1636645.7071,1547971.0348,1531526.6345,1396502.0347,1325517.7693,1247904.9351,1223074.5695,1191765.4584,1183283.5095,1181422.0349,1130917.9376,1130656.9944,1116415.5479000001,1077754.0825,1055647.8222999999,1048075.4393,933134.8605,930577.8893,927315.127,925694.0499,918267.6427,912771.1579,881239.6855,857644.6690999999,845330.4951000001,822755.6666,805207.4352,731638.696,712181.8837,694633.2557,685696.7758,683199.7032,646059.2383,645403.5736,640519.3984,635598.8298,628635.9906,622561.7652,614226.6775,600360.6001,589807.1469,579107.3077,577672.4211,576781.4972,574247.8318,571721.5168,556780.0535,556488.0809,553125.1955,543015.2119999999,538918.1867,525602.0118,515334.1329,505577.5193,498366.3073,486195.0386,482071.5599,479375.2956,472577.512,463199.9469,457240.2789,455656.82389999996,447808.8906,446719.3681,443138.5563,437118.7481,436680.39009999996,428321.674,425779.9142,423647.2566,420067.2969,416903.8039,405197.3294,402013.5048,391302.8889,385524.8919,384647.8623,383559.0443,382739.0974,379976.3676,378228.3584,377009.4748,376856.0211,365714.3232,365147.865,360576.8282,357349.9085,357112.6357,350913.1592,345289.6665,345083.5578,336495.3318,335127.3678,328057.5404,326016.0657,318138.1483,317857.7695,310303.4508,298992.1114,298624.4441,296971.9589,289939.0104,289121.942,287435.0604,278801.4056,266286.7496,262650.6953,256850.1229,252167.6116,250487.6803,250124.8843,247960.5772,245053.9986,244413.906,241807.1721,239309.195,239159.5333,239027.9754,235934.9434,231901.66460000002,228782.30730000001,225543.97830000002,224931.6565,221305.0102,218303.8046,217157.4441,214923.9535,213538.3396,209424.62159999998,206248.0009,204492.7316,203691.4106,202471.6264,199079.6582,196175.3934,192623.0161,181371.1613,177808.0796,164944.9022,161057.3006,160451.3347,155870.7573,149383.5031,146332.2604,143982.4333,142817.0669,135582.234,124029.813,108214.6836,97544.6321,92674.5128,89850.6637,80665.1974,60370.6896],\"sizemode\":\"area\",\"sizeref\":47541.19191825,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"type\":\"scattergeo\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"geo\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"center\":{},\"scope\":\"usa\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"weight\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('db0af0dd-52a0-4c6d-8d6b-76491882228c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Nu7m15GcZfnS",
        "Wf-TQOlWDpR-",
        "ecfQhoBJw4Me"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}